import os
import re
import sys
import math
import numpy as np
import pandas as pd
from datetime import datetime
from typing import Optional, Dict, Any, List, Tuple

# pycache ã‚’ç”Ÿæˆã—ãªã„
sys.dont_write_bytecode = True

# web/src ã‚’ import ãƒ‘ã‚¹ã«è¿½åŠ ï¼ˆconfig ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’è§£æ±ºã™ã‚‹ãŸã‚ï¼‰
PROJECT_SRC = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))  # web/src
if PROJECT_SRC not in sys.path:
    sys.path.insert(0, PROJECT_SRC)

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’æ­£ã—ãè¨ˆç®—ã—ã¦ libs ã‚’è¿½åŠ ï¼ˆlibs ã¯ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆç›´ä¸‹ï¼‰
PROJECT_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", "..", ".."))  # project root (keiba_ai_ver2.0)
LIBS_PATH = os.path.join(PROJECT_ROOT, "libs")
if LIBS_PATH not in sys.path:
    sys.path.insert(0, LIBS_PATH)

from config.path import HORSE_ID_MAP_PATH, PAST_PERF_PATH, HORSE_PEDS_PATH, PEDS_RESULTS_PATH, TIME_INFO_PATH, RACE_CALENDAR_FOLDER_PATH
import name_header
import race_pages

try:
    from config.settings import RANK_COLORS, WAKU_COLORS
except Exception:
    # templates.py ã®å®šç¾©åãŒç•°ãªã‚‹ï¼æœªå®šç¾©ã®å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    from config import templates as templates_mod
    RANK_COLORS = getattr(templates_mod, "RANK_COLORS", {})
    WAKU_COLORS = getattr(templates_mod, "WAKU_COLORS", {})

# ---- ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ ----

def safe_read_csv(path: str, dtype=None) -> pd.DataFrame:
    if not os.path.exists(path):
        return pd.DataFrame()
    try:
        return pd.read_csv(path, dtype=dtype, index_col=None)
    except Exception:
        return pd.read_csv(path, dtype=str, index_col=None)

def time_str_to_ms(t: str) -> Optional[int]:
    """
    '0:1:08.9', '1:32.7', '59.6' ç­‰ã‚’ãƒŸãƒªç§’ã«å¤‰æ›ã€‚
    æˆ»ã‚Šå€¤ã¯ãƒŸãƒªç§’ï¼ˆintï¼‰ã€‚è§£æã§ããªã„å ´åˆã¯ Noneã€‚
    """
    if pd.isna(t) or t is None:
        return None
    s = str(t).strip()
    if s == "" or s.lower() in ["nan", "---"]:
        return None
    # å½¢å¼ã‚’åˆ†è§£
    try:
        # ä¾‹: '0:1:08.9' -> ['0','1','08.9']  or '1:32.7' -> ['1','32.7']
        parts = s.split(":")
        if len(parts) == 3:
            h = int(parts[0])
            m = int(parts[1])
            sec = float(parts[2])
            total_ms = ((h * 60 + m) * 60 + sec) * 1000
        elif len(parts) == 2:
            m = int(parts[0])
            sec = float(parts[1])
            total_ms = (m * 60 + sec) * 1000
        else:
            # ç§’ã®ã¿
            sec = float(parts[0])
            total_ms = sec * 1000
        return int(round(total_ms))
    except Exception:
        # å¤±æ•—ã—ãŸã‚‰ None
        return None

def ms_to_time_str(ms: Optional[int]) -> str:
    """ãƒŸãƒªç§’ -> 'M:SS.s' è¡¨ç¤ºï¼ˆmsãŒNoneã¯ '-'ï¼‰"""
    if ms is None:
        return "-"
    sec = ms / 1000.0
    m = int(sec // 60)
    s = sec - m * 60
    # å°æ•°ç¬¬ä¸€ä½ã«ä¸¸ã‚ã¦è¡¨ç¤º (ä¾‹ 1:32.7)
    return f"{m}:{s:04.1f}"

def normalize_passage(pass_str: str, heads: Optional[int], target_heads=18) -> List[Optional[float]]:
    """
    é€šéæ–‡å­—åˆ—ã‚’æ•°å€¤åŒ–ã—ã¦æ­£è¦åŒ–ï¼ˆtarget_headsã‚¹ã‚±ãƒ¼ãƒ«ï¼‰ã—ãƒªã‚¹ãƒˆè¿”å´ã€‚
    ä¾‹: '6-5-4-4' -> [6_norm,5_norm,4_norm,4_norm]
    headsï¼ˆå‡ºèµ°é ­æ•°ï¼‰ãŒç„¡ã‘ã‚Œã° None ã‚’å…¥ã‚Œã‚‹ã€‚
    """
    if pd.isna(pass_str) or pass_str is None or str(pass_str).strip() == "":
        return []
    parts = [p.strip() for p in str(pass_str).split("-") if p.strip() != ""]
    out = []
    for p in parts:
        try:
            pos = int(p)
            if heads and not pd.isna(heads) and float(heads) > 0:
                norm = pos * (target_heads / float(heads))
            else:
                norm = None
            out.append(norm)
        except:
            out.append(None)
    return out

# ---- ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿é–¢æ•° ----

def load_horse_id_map(path: str = HORSE_ID_MAP_PATH) -> pd.DataFrame:
    df = safe_read_csv(path, dtype=str)
    # æƒ³å®š: columns = ['horse_id','horse_name'] ã‹ ['index','horse_name'] ç­‰ã„ã‚ã„ã‚ã‚ã‚‹å¯èƒ½æ€§ã‚ã‚Š
    # æ­£è¦åŒ–ã—ã¦ 'horse_id','horse_name' ã‚«ãƒ©ãƒ ã‚’è¿”ã™
    if df.empty:
        return df
    # ã‚‚ã— index ãŒ é¦¬ID ã§ é¦¬åãŒ 0 åˆ—ã«ã‚ã‚‹å ´åˆ
    if "horse_id" not in df.columns and "é¦¬å" not in df.columns:
        cols = df.columns.tolist()
        if len(cols) >= 2:
            # try horse_id in col0, horse_name in col1
            df = df.rename(columns={cols[0]: "horse_id", cols[1]: "é¦¬å"})
        else:
            # fallback: treat index as horse_id and first column as name
            df = df.reset_index().rename(columns={"index": "horse_id", df.columns[0]: "é¦¬å"})
    # strip
    df["é¦¬å"] = df["é¦¬å"].astype(str).str.strip()
    df["é¦¬å"] = df["é¦¬å"].astype(str).str.strip()
    return df[["horse_id", "é¦¬å"]]

def get_avg_time(course_name, race_type, class_name, course_len, ground_state):
    """
    é–‹å‚¬å ´åã¨æ¡ä»¶ã‹ã‚‰å¹³å‡ã‚¿ã‚¤ãƒ ã‚’å–å¾—ã™ã‚‹é–¢æ•°

    Args:
        course_name (str): é–‹å‚¬å ´åï¼ˆä¾‹: "ä¸­äº¬"ï¼‰
        race_type (str): ãƒ¬ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—ï¼ˆä¾‹: "èŠ" or "ãƒ€ãƒ¼ãƒˆ"ï¼‰
        class_name (str): ã‚¯ãƒ©ã‚¹åï¼ˆä¾‹: "3å‹ã‚¯ãƒ©ã‚¹", "æœªå‹åˆ©", "ã‚ªãƒ¼ãƒ—ãƒ³"ï¼‰
        course_len (int or str): è·é›¢ï¼ˆä¾‹: 1800ï¼‰
        ground_state (str): é¦¬å ´çŠ¶æ…‹ï¼ˆä¾‹: "è‰¯", "ç¨é‡", "é‡", "ä¸"ï¼‰

    Returns:
        float or None: è©²å½“æ¡ä»¶ã®å¹³å‡ã‚¿ã‚¤ãƒ ï¼ˆå­˜åœ¨ã—ãªã„å ´åˆã¯ np.nanï¼‰
    """

    # --- é–‹å‚¬å ´ã‹ã‚‰place_idå–å¾— ---
    try:
        place_id = name_header.NAME_LIST.index(course_name) + 1
    except ValueError:
        print(f"âŒ ä¸æ˜ãªé–‹å‚¬å ´å: {course_name}")
        return np.nan

    # --- ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ç”Ÿæˆ ---
    avg_time_path = os.path.join(TIME_INFO_PATH, name_header.PLACE_LIST[place_id - 1], "total_avg_time.csv")
    if not os.path.exists(avg_time_path):
        print(f"âš ï¸ å¹³å‡ã‚¿ã‚¤ãƒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {avg_time_path}")
        return np.nan
    try:
        df = pd.read_csv(avg_time_path, dtype=str)
    except Exception as e:
        print(f"âš ï¸ CSVèª­ã¿è¾¼ã¿å¤±æ•—: {avg_time_path} ({e})")
        return np.nan

    # --- å‹å¤‰æ› ---
    df["course_len"] = df["course_len"].astype(str).str.strip()
    df["avg_time"] = pd.to_numeric(df["avg_time"], errors="coerce")
    # --- å€¤ã®èª¿æ•´ ---
    if ground_state == "ä¸è‰¯":
        ground_state = "ä¸"
    if ground_state == "ç¨":
        ground_state = "ç¨é‡"
    if race_type == "ãƒ€":
        race_type = "ãƒ€ãƒ¼ãƒˆ"

    # --- æ¡ä»¶ãƒ•ã‚£ãƒ«ã‚¿ ---
    cond = (
        (df["race_type"] == str(race_type)) &
        (df["course_len"] == str(course_len)) &
        (df["ground_state"] == str(ground_state)) &
        (df["class"] == str(class_name))
    )
    sub = df[cond]

    if sub.empty or sub["avg_time"].isna().all():
        print(f"âš ï¸ è©²å½“ãƒ‡ãƒ¼ã‚¿ãªã—: {course_name} {race_type} {class_name} {course_len} {ground_state}")
        return np.nan

    # --- å¹³å‡å€¤ã‚’è¿”ã™ï¼ˆè¤‡æ•°ä¸€è‡´æ™‚ã¯å¹³å‡ï¼‰ ---
    return float(sub["avg_time"].values[0])

def get_horse_id_by_name(horse_name: str, map_df: pd.DataFrame) -> Optional[str]:
    if map_df is None or map_df.empty:
        return None
    # å®Œå…¨ä¸€è‡´, éƒ¨åˆ†ä¸€è‡´ã®é †ã§æ¤œç´¢
    sel = map_df[map_df["é¦¬å"] == horse_name]
    if not sel.empty:
        return sel.iloc[0]["horse_id"]
    # éƒ¨åˆ†ä¸€è‡´ï¼ˆå‰æ–¹ä¸€è‡´ï¼‰
    sel = map_df[map_df["é¦¬å"].str.contains(horse_name, na=False)]
    if not sel.empty:
        return sel.iloc[0]["é¦¬å"]
    return None

def load_horse_peds(horse_id: str) -> Dict[str, Any]:
    path = os.path.join(HORSE_PEDS_PATH, f"{horse_id}.csv")
    df = safe_read_csv(path, dtype=str)
    if df.empty:
        return {}
    # df å½¢å¼ãŒ (index,row) ã«ãªã£ã¦ã„ã‚‹ã‚µãƒ³ãƒ—ãƒ«ã‚’è€ƒæ…®
    try:
        d = {}
        for idx, val in df.values:
            d[str(idx).strip()] = str(val).strip()
        # ã¾ãŸã¯ã€ç¸¦ã« peds_0, peds_1 ã®ã‚ˆã†ãªã‚«ãƒ©ãƒ ãŒã‚ã‚‹å ´åˆ
        if not d:
            for col in df.columns:
                d[col] = df.iloc[0].get(col, "")
    except Exception:
        d = {}
    return d

def load_peds_results(place_id: int, race_type: str, course_len: int, ground_state: str) -> pd.DataFrame:
    """
    PedsResults/{place_name}/Total/{condition_file}.csv ã‚’è¿”ã™
    condition_file ã¯ e.g. 'ãƒ€ãƒ¼ãƒˆ_1400m_è‰¯.csv' ã®ã‚ˆã†ãªãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆæ‹¡å¼µå­ãªã—ã§ã‚‚å¯ï¼‰ã€‚
    """
    fname = race_type + "_" + str(course_len) + "m_" + ground_state
    if not fname.lower().endswith(".csv"):
        fname = fname + ".csv"
    path = os.path.join(PEDS_RESULTS_PATH, name_header.PLACE_LIST[place_id - 1], "Total", fname)
    return safe_read_csv(path, dtype=str)

def load_past_performance(horse_id: str) -> pd.DataFrame:
    path = os.path.join(PAST_PERF_PATH, f"{horse_id}.csv")
    df = safe_read_csv(path, dtype=str)
    if df.empty:
        return df
    # æ—¥ä»˜åˆ—ãŒã‚ã‚Œã° parse
    if "æ—¥ä»˜" in df.columns:
        try:
            df["æ—¥ä»˜_parsed"] = pd.to_datetime(df["æ—¥ä»˜"], errors="coerce", dayfirst=False)
        except Exception:
            df["æ—¥ä»˜_parsed"] = pd.to_datetime(df["æ—¥ä»˜"], errors="coerce")
    # normalize column names: remove leading/trailing spaces
    df.columns = [c.strip() for c in df.columns]
    return df

# ---- è§£æé–¢æ•° ----
def peds_results_for_bloodline(place_id: int, race_type: str, course_len: int, ground_state: str, peds0_name: str ) -> pd.DataFrame:
    """
    æŒ‡å®šè¡€çµ±ï¼ˆpeds0_nameï¼‰ã® PedsResults ãŒå­˜åœ¨ã™ã‚Œã° dataframe ã‚’è¿”ã™ã€‚
    ãƒ•ã‚¡ã‚¤ãƒ«å†…ã® 'ã‚¯ãƒ©ã‚¹' åˆ—ã”ã¨ã«ãƒ•ã‚£ãƒ«ã‚¿ã—ã¦è¿”ã™ï¼ˆå‘¼ã³å‡ºã—å´ã§åˆ©ç”¨ï¼‰ã€‚
    """
    df = load_peds_results(place_id, race_type, course_len, "all")
    if df.empty:
        return pd.DataFrame()
    # normalize columns
    df.columns = [c.strip() for c in df.columns]
    pattern = rf"\b{re.escape(peds0_name)}\b"

    # è¡€çµ±ã‚«ãƒ©ãƒ ãŒ 'è¡€çµ±' ã«ãªã£ã¦ã„ã‚‹æƒ³å®š
    if "è¡€çµ±" in df.columns:
        res = df[df["è¡€çµ±"].astype(str).str.contains(pattern, na=False, regex=True)]
        return res.copy()
    # åˆ—åã®æºã‚‰ããŒã‚ã‚Œã° try ãã®ä»–
    for col in df.columns:
        if "è¡€çµ±" in col:
            res = df[df[col].astype(str).str.contains(pattern, na=False, regex=True)]
            return res.copy()
    return pd.DataFrame()

# NaN åˆ¤å®šã—ã¦ "-" ã«ç½®ãæ›ãˆ
def safe_value(val):
    if val is None or val is "None":
        return "-"
    try:
        if isinstance(val, float) and math.isnan(val):
            return "-"
        if pd.isna(val):
            return "-"
    except Exception:
        pass
    return val

def recent_5_performances(horse_id: str, date_str:str) -> List[Dict[str, Any]]:
    """
    PastPerformance/{horse_id}.csv ã‹ã‚‰ç›´è¿‘5èµ°ã‚’å–å¾—ã—ã¦æ•´å½¢ã—ã¦è¿”ã™ã€‚
    å„ã‚¨ãƒ³ãƒˆãƒªã«æ—¥ä»˜ã€ãƒ¬ãƒ¼ã‚¹åã€ã‚³ãƒ¼ã‚¹ï¼ˆè·é›¢/ç¨®åˆ¥ï¼‰ã€é¦¬å ´ã€ã‚¿ã‚¤ãƒ (ms)ã€ç€å·®(ms)ã€ä¸Šã‚Šã€é€šé(æ­£è¦åŒ–) ç­‰ã‚’å«ã‚€ã€‚
    """
    df = load_past_performance(horse_id)
    if df.empty:
        return []

    # --- æ—¥ä»˜ã®æ­£è¦åŒ– ---
    if "æ—¥ä»˜" in df.columns:
        df["æ—¥ä»˜_parsed"] = pd.to_datetime(df["æ—¥ä»˜"], errors="coerce")
    else:
        print(f"âš ï¸ 'æ—¥ä»˜'åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ (horse_id={horse_id})")
        return []

    # --- race_day ã‚’ datetime ã«å¤‰æ› ---
    try:
        race_day_dt = datetime.strptime(str(date_str), "%Y%m%d")
    except ValueError:
        print(f"âš ï¸ race_dayã®å½¢å¼ãŒä¸æ­£ã§ã™: {date_str}")
        return []

    # --- race_day ã‚ˆã‚Šå‰ã®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ ---
    df = df[df["æ—¥ä»˜_parsed"] < race_day_dt]

    if df.empty:
        return []

    # --- ã‚½ãƒ¼ãƒˆå‡¦ç† ---
    if df["æ—¥ä»˜_parsed"].notna().any():
        df_sorted = df.sort_values("æ—¥ä»˜_parsed", ascending=False)
    else:
        df_sorted = df.iloc[::-1].copy()  # æ—¥ä»˜ãŒNaNãªã‚‰é€†é †ã§æƒ³å®š

    # --- æœ€æ–°5ä»¶ãªã©ã‚’æŠ½å‡ºã™ã‚‹å ´åˆ ---
    res = []
    count = 0
    for _, row in df_sorted.iterrows():
        if count >= 5:
            break
        count += 1
        # åŸºæœ¬ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰
        race_id = row.get("race_id", "")
        date_raw = row.get("æ—¥ä»˜", "")
        waku = row.get("æ ç•ª", "")
        umaban = row.get("é¦¬ç•ª", "")
        race_num = row.get("R", "")
        race_name = row.get("ãƒ¬ãƒ¼ã‚¹å", row.get("ãƒ¬ãƒ¼ã‚¹å", ""))
        pops = row.get("äººæ°—", "")
        try:
            pops = int(float(pops))
        except:
            pops = pops
        result = row.get("ç€é †", "")
        race_type = row.get("race_type", "")
        course_len = row.get("course_len", "")
        class_name = row.get("class", "")
        course = str(course_len)
        ground = row.get("ground_state","")
        time_raw = row.get("ã‚¿ã‚¤ãƒ ", "")
        t_ms = time_str_to_ms(time_raw)
        place_match = re.search(r"[0-9]*(æ±äº¬|ä¸­å±±|é˜ªç¥|äº¬éƒ½|æœ­å¹Œ|å‡½é¤¨|ç¦å³¶|æ–°æ½Ÿ|ä¸­äº¬|å°å€‰)[0-9]*", row.get("é–‹å‚¬", ""))
        course_name = place_match.group(1) if place_match else ""
        diff_raw = row.get("ç€å·®", "")
        # åŒæ¡ä»¶ã®å¹³å‡ã‚¿ã‚¤ãƒ ã‚’å–å¾—
        avg_time = get_avg_time(course_name, race_type, class_name, course_len, ground)
        if not avg_time is np.nan:
            try:
                diff_avg_ms = (t_ms - avg_time) / 1000
                diff_avg_ms = round(diff_avg_ms, 2)
            except Exception:
                diff_avg_ms = np.nan
        else:
            diff_avg_ms = np.nan
        try:
            time_raw = re.sub(r"^0:", "", time_raw)
        except Exception:
            time_raw = np.nan

        # é€šéã®æ­£è¦åŒ–
        heads = None
        if "é ­ æ•°" in row:
            try:
                heads = int(str(row.get("é ­ æ•°")).strip())
            except:
                heads = None
        elif "é ­æ•°" in row:
            try:
                heads = int(str(row.get("é ­æ•°")).strip())
            except:
                heads = None
        passage = row.get("é€šé", row.get("é€šé", ""))
        passage_norm = normalize_passage(passage, heads)
        # ãƒ¬ãƒ¼ã‚¹åãŒå–å¾—ã§ããªã‹ã£ãŸå ´åˆã€race_id_listã‹ã‚‰å–å¾—ã™ã‚‹
        if race_name is np.nan or None:
            # ãƒ¬ãƒ¼ã‚¹åãƒ»æ™‚åˆ»å–å¾—
            race_date = datetime.strptime(date_raw, "%Y/%m/%d").strftime("%Y%m%d")
            race_info_path = os.path.join(RACE_CALENDAR_FOLDER_PATH, f"race_time_id_list/{race_date}.csv")
            if os.path.exists(race_info_path):
                df_info = pd.read_csv(race_info_path, dtype=str)
                match = df_info[df_info["race_id"].astype(str) == str(race_id)]
                if not match.empty:
                    race_name = str(match.iloc[0]["race_name"])

        res.append({
            "date": safe_value(date_raw),
            "date_parsed": safe_value(row.get("æ—¥ä»˜_parsed", None)),
            "race_name": safe_value(race_name),
            "race_num" : safe_value(race_num),
            "waku" : safe_value(waku),
            "umaban" : safe_value(umaban),
            "pops" : safe_value(pops),
            "result" : safe_value(result),
            "course_name" : safe_value(course_name),
            "course": safe_value(course),
            "race_type" : safe_value(race_type),
            "ground": safe_value(ground),
            "class_name": safe_value(class_name),
            "time_raw": safe_value(time_raw),
            "time_ms": safe_value(t_ms),
            "diff_avg_ms" : safe_value(diff_avg_ms),
            "diff_ms": safe_value(diff_raw),
            "ä¸Šã‚Š": safe_value(row.get("ä¸Šã‚Š", None)),
            "é€šé": safe_value(passage),
            "é€šé_norm": safe_value(passage_norm),
            "é¦¬ä½“é‡": safe_value(row.get("é¦¬ä½“é‡", None)),
            "æ ": safe_value(row.get("æ  ç•ª", row.get("æ  ç•ª", row.get("æ ", None)))),
            "é¦¬ç•ª": safe_value(row.get("é¦¬ ç•ª", row.get("é¦¬ ç•ª", row.get("é¦¬ç•ª", None)))),
            "äººæ°—": safe_value(row.get("äºº æ°—", row.get("äºº æ°—", row.get("äººæ°—", None)))),
            "ç€é †": safe_value(row.get("ç€ é †", row.get("ç€ é †", row.get("ç€é †", None)))),
            "æ–¤é‡": safe_value(row.get("æ–¤ é‡", row.get("æ–¤ é‡", row.get("æ–¤é‡", None)))),
        })
    return res

def turf_dirt_summary(horse_id: str, date_str: str) -> Dict[str, Any]:
    """
    PastPerformance ã‹ã‚‰èŠ/ãƒ€ãƒ¼ãƒˆã”ã¨ã«:
      - æœ€é€Ÿä¸Šã‚Š (msã§ã¯ãªãè¡¨ç¤ºã¯ä¸Šã‚Šã®å€¤ãã®ã‚‚ã®ã€‚è©²å½“ãƒ¬ãƒ¼ã‚¹æƒ…å ±ä»˜)
      - å¹³å‡ä¸Šã‚Š
      - å¹³å‡é€šéä½ç½®ï¼ˆæœ€å¾Œã®é€šéä½ç½®ã‚’ normalizedã—ã¦å¹³å‡ï¼‰
    ã‚’è¨ˆç®—ã—ã¦è¿”ã™ã€‚
    """
    df = load_past_performance(horse_id)
    if df.empty:
        return {"èŠ": {}, "ãƒ€ãƒ¼ãƒˆ": {}}

    # normalize column names
    df = df.copy()
    if "ä¸Šã‚Š" in df.columns:
        df["ä¸Šã‚Š_num"] = pd.to_numeric(df["ä¸Šã‚Š"], errors="coerce")
    else:
        df["ä¸Šã‚Š_num"] = pd.Series(dtype=float)
     # --- æ—¥ä»˜ã®æ­£è¦åŒ– ---
    if "æ—¥ä»˜" in df.columns:
        df["æ—¥ä»˜_parsed"] = pd.to_datetime(df["æ—¥ä»˜"], errors="coerce")
    else:
        print(f"âš ï¸ 'æ—¥ä»˜'åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ (horse_id={horse_id})")
        return []
    try:
        race_day_dt = datetime.strptime(str(date_str), "%Y%m%d")
    except ValueError:
        print(f"âš ï¸ race_dayã®å½¢å¼ãŒä¸æ­£ã§ã™: {date_str}")
        return []
    # --- race_day ã‚ˆã‚Šå‰ã®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ ---
    df = df[df["æ—¥ä»˜_parsed"] < race_day_dt]

    # ç°¡å˜ã« race surface åˆ¤å®š : 'èŠ' ã¾ãŸã¯ 'ãƒ€ãƒ¼ãƒˆ' ã‚’ 'é¦¬ å ´' ã‚«ãƒ©ãƒ ã§åˆ¤å®š
    surface_summary = {}
    for surface in ["èŠ", "ãƒ€ãƒ¼ãƒˆ"]:
        search_word = surface[0]
        sub = df[df.apply(lambda r: search_word in str(r.get("race_type", "")), axis=1)]
        if sub.empty:
            surface_summary[surface] = {"fastest_up": None, "fastest_up_info": None, "avg_up": None, "avg_pass_norm": None}
            continue
        # æœ€é€Ÿä¸Šã‚Š
        if "ä¸Šã‚Š_num" in sub.columns:
            s2 = sub.copy()
            s2 = s2[s2["ä¸Šã‚Š_num"].notna()]
            if not s2.empty:
                idx = s2["ä¸Šã‚Š_num"].idxmin()
                fastest_row = s2.loc[idx]
                fastest_up = fastest_row["ä¸Šã‚Š_num"]
                place_match = re.search(r"[0-9]*(æ±äº¬|ä¸­å±±|é˜ªç¥|äº¬éƒ½|æœ­å¹Œ|å‡½é¤¨|ç¦å³¶|æ–°æ½Ÿ|ä¸­äº¬|å°å€‰)[0-9]*", fastest_row.get("é–‹å‚¬", ""))
                course_name = place_match.group(1) if place_match else ""
                fastest_info = {
                    "date": fastest_row.get("æ—¥ä»˜", ""),
                    "race_name": fastest_row.get("ãƒ¬ãƒ¼ã‚¹å", ""),
                    "course_name": course_name,
                    "course_len": fastest_row.get("course_len", ""),
                    "é¦¬å ´": fastest_row.get("ground_state", "")
                }
            else:
                fastest_up = None
                fastest_info = None
            avg_up = s2["ä¸Šã‚Š_num"].mean() if not s2.empty else None
        else:
            fastest_up = None
            fastest_info = None
            avg_up = None

        # å¹³å‡é€šéï¼ˆæœ€çµ‚é€šéä½ç½®ã‚’è¦‹ã¦ normalizeï¼‰
        norm_list = []
        for _, r in sub.iterrows():
            heads = None
            if "é ­ æ•°" in r and not pd.isna(r.get("é ­ æ•°")):
                try:
                    heads = int(r.get("é ­ æ•°"))
                except:
                    heads = None
            elif "é ­æ•°" in r and not pd.isna(r.get("é ­æ•°")):
                try:
                    heads = int(r.get("é ­æ•°"))
                except:
                    heads = None
            p = r.get("é€šé", "")
            arr = normalize_passage(p, heads)
            norm_list.append(arr)

        avg_pass_norm = calc_average_norm_passages(norm_list)

        # ãƒ‡ãƒ¼ã‚¿ã®æ­£è¦åŒ–
        avg_up = safe_value(avg_up)
        try:
            avg_up = round(float(avg_up), 2) 
        except:
            avg_up = "-"
        avg_pass_norm = safe_value(avg_pass_norm)

        surface_summary[surface] = {
            "fastest_up": fastest_up,
            "fastest_up_info": fastest_info,
            "avg_up": avg_up,
            "avg_pass_norm": avg_pass_norm,
            "count": len(sub)
        }
    return surface_summary

def calc_average_norm_passages(norm_list):
    """
    æ­£è¦åŒ–æ¸ˆã¿é€šéä½ç½®ã®ãƒªã‚¹ãƒˆï¼ˆä¾‹: [[3.3, 4.5], [16.8, 16.8]]ï¼‰ã‚’
    å³è©°ã‚ã§æ•´åˆ—ã—ã€å„ã‚³ãƒ¼ãƒŠãƒ¼ã”ã¨ã®å¹³å‡ã‚’è¿”ã™ã€‚
    """
    if not norm_list:
        return None

    # æœ€å¤§é•·ã‚’æ±‚ã‚ã‚‹
    max_len = max(len(x) for x in norm_list if isinstance(x, list))

    # å³è©°ã‚æ•´åˆ—
    aligned = []
    for arr in norm_list:
        if not isinstance(arr, list) or len(arr) == 0:
            continue
        pad_len = max_len - len(arr)
        aligned.append([None] * pad_len + arr)

    # å¹³å‡è¨ˆç®—ï¼ˆNoneã‚’é™¤å¤–ï¼‰
    avg_by_corner = []
    for i in range(max_len):
        vals = [row[i] for row in aligned if row[i] is not None]
        if vals:
            avg = round(sum(vals) / len(vals), 1)
            avg_by_corner.append(avg)
        else:
            avg_by_corner.append(None)

    return avg_by_corner


def same_course_best_time(
    horse_id: str,
    target_course_len: int,
    target_race_type: str,
    target_place_id: int,
    date_str : str
) -> Optional[Dict[str, Any]]:
    """
    PastPerformance ã‹ã‚‰åŒã˜é–‹å‚¬å ´(place_id)ã€è·é›¢ã€é¦¬å ´ã‚¿ã‚¤ãƒ—(èŠ/ãƒ€ãƒ¼ãƒˆ)ã®æŒã¡æ™‚è¨ˆã‚’è¿”ã™ã€‚
    è¿”å€¤:
        {
            'time_ms': int,
            'time_str': '1:28.4',
            'date': '2024/10/13',
            'race_name': '2æ­³æœªå‹åˆ©',
            'ground': 'è‰¯',
            'place_id': '05_tokyo',
            'info_row': {...}
        }
    """
    df = load_past_performance(horse_id)
    if df.empty:
        return None

    df = df.fillna("").astype(str)
     # --- æ—¥ä»˜ã®æ­£è¦åŒ– ---
    if "æ—¥ä»˜" in df.columns:
        df["æ—¥ä»˜_parsed"] = pd.to_datetime(df["æ—¥ä»˜"], errors="coerce")
    else:
        print(f"âš ï¸ 'æ—¥ä»˜'åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ (horse_id={horse_id})")
        return []
    try:
        race_day_dt = datetime.strptime(str(date_str), "%Y%m%d")
    except ValueError:
        print(f"âš ï¸ race_dayã®å½¢å¼ãŒä¸æ­£ã§ã™: {date_str}")
        return []
    # --- race_day ã‚ˆã‚Šå‰ã®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ ---
    df = df[df["æ—¥ä»˜_parsed"] < race_day_dt]

    candidates = []

    for _, row in df.iterrows():
        _raw = str(row.get("é–‹å‚¬", ""))
        # --- é–‹å‚¬å ´åã‚’æŠ½å‡º ---
        match = re.search(r"[0-9]*(æœ­å¹Œ|å‡½é¤¨|ç¦å³¶|æ–°æ½Ÿ|æ±äº¬|ä¸­å±±|ä¸­äº¬|äº¬éƒ½|é˜ªç¥|å°å€‰)[0-9]*", _raw)
        place_name = match.group(1) if match else ""

        if not place_name:
            continue

        # --- é–‹å‚¬å ´å â†’ place_id ã«å¤‰æ› ---
        try:
            place_id = int(name_header.NAME_LIST.index(place_name)) + 1
        except ValueError:
            continue
       
        # --- è·é›¢æ¬„è§£æ ---
        dist_raw = str(row.get("race_type", "")).strip()
        if dist_raw.startswith("éšœ"):
            continue
        race_type = "èŠ" if "èŠ" in dist_raw else "ãƒ€ãƒ¼ãƒˆ" if "ãƒ€" in dist_raw else ""

        dist = int(row.get("course_len", ""))
        if not race_type or not dist:
            continue

        # --- ãƒ•ã‚£ãƒ«ã‚¿æ¡ä»¶ ---
        if place_id == target_place_id and race_type == target_race_type and dist == target_course_len:
            t_ms = time_str_to_ms(row.get("ã‚¿ã‚¤ãƒ ", ""))
            if t_ms is not None:
                candidates.append((t_ms, row, place_id))

    if not candidates:
        return None

    # --- æœ€é€Ÿã‚¿ã‚¤ãƒ ã‚’é¸æŠ ---
    best_time_ms, best_row, place_id = sorted(candidates, key=lambda x: x[0])[0]

    return {
        "time_ms": best_time_ms,
        "time_str": ms_to_time_str(best_time_ms),
        "date": best_row.get("æ—¥ä»˜", ""),
        "race_name": best_row.get("ãƒ¬ãƒ¼ã‚¹å", ""),
        "ground": best_row.get("ground_state", best_row.get("ground_state", "")),
        "place_id": place_id,
        "info_row": best_row.to_dict() if hasattr(best_row, "to_dict") else {}
    }

# è¡€çµ±åã‚’æŠ½å‡ºã™ã‚‹
def extract_peds_name(peds0: str) -> str | None:
    if not peds0:
        return None
    
    # å‰å¾Œã®ç©ºç™½ã‚’å‰Šé™¤
    peds0 = peds0.strip()
    
    # å…ˆé ­ãŒã‚«ã‚¿ã‚«ãƒŠãªã‚‰ã‚«ã‚¿ã‚«ãƒŠéƒ¨åˆ†ã ã‘æŠ½å‡º
    match = re.match(r"^([\u30A0-\u30FFãƒ¼]+)", peds0)
    if match:
        return match.group(1)
    
    # å…ˆé ­ãŒè‹±å­—ãªã‚‰è‹±å­—éƒ¨åˆ†ã ã‘æŠ½å‡º
    match = re.match(r"^([A-Za-z\s]+)", peds0)
    if match:
        return match.group(1).strip()
    
    # ã©ã¡ã‚‰ã§ã‚‚ãªã‘ã‚Œã°ãã®ã¾ã¾è¿”ã™
    return peds0

# ---- çµ±åˆï¼šé¦¬ã”ã¨ã®å…¨å‡ºåŠ›ã‚’ä½œã‚‹é–¢æ•° ----
def build_horse_report(horse_name: str, place_id: int, race_id: str, date_str: str) -> Dict[str, Any]:
    """
    horse_name ã‹ã‚‰ horse_id ã‚’ç‰¹å®šã—ã€â‘ ï½â‘£ã®æƒ…å ±ã‚’é›†ã‚ã¦ dict ã§è¿”ã™ã€‚
    - place_name: PedsResults ã® place ãƒ•ã‚©ãƒ«ãƒ€å (e.g. '01_sapporo')
    - condition_file: PedsResults ãƒ•ã‚¡ã‚¤ãƒ«å (ä¾‹ 'ãƒ€ãƒ¼ãƒˆ_1400m_è‰¯.csv' ã¾ãŸã¯æ¡ä»¶ã‚­ãƒ¼)
    - race_type, course_len: (ä»»æ„) ç¾åœ¨è¦‹ã¦ã„ã‚‹ãƒ¬ãƒ¼ã‚¹ã®ç¨®åˆ¥ãƒ»è·é›¢ï¼ˆåŒã‚³ãƒ¼ã‚¹æ¤œç´¢ç”¨ï¼‰
    """
    # --- åŸºæº–ãƒ¬ãƒ¼ã‚¹æƒ…å ±å–å¾— ---
    year = race_id[:4]
    race_type, course_len, ground_state, race_class = race_pages.get_race_info(year, place_id, race_id)
    if race_type == None and course_len == None and ground_state == None and race_class == None:
        return
    
    map_df = load_horse_id_map(HORSE_ID_MAP_PATH)
    hid = get_horse_id_by_name(horse_name, map_df)
    if not hid:
        return {"error": f"horse_id not found for {horse_name}"}

    # â‘  è¡€çµ±(peds_0) ã¨ PedsResultsï¼ˆåŒã‚³ãƒ¼ã‚¹ã®1,2,3,ç€å¤–ãƒ‡ãƒ¼ã‚¿ï¼‰
    peds = load_horse_peds(hid)
    peds0 = peds.get("peds_0") or peds.get("peds0") or peds.get("peds_0 ", None)
    peds0 = extract_peds_name(peds0)
    peds_results = None
    if peds0:
        peds_results = peds_results_for_bloodline(place_id, race_type, course_len, ground_state, peds0)
     # --- ã‚¯ãƒ©ã‚¹ã§ãƒ•ã‚£ãƒ«ã‚¿ ---
    filtered_df = peds_results[peds_results["ã‚¯ãƒ©ã‚¹"].isin([race_class, "all"])].copy()
    if filtered_df.empty:
        print(f"âš ï¸ {peds0}: è©²å½“ã‚³ãƒ¼ã‚¹({place_id}:{race_type}{course_len}) ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        # return pd.DataFrame()
    else :
        # --- å‹ç‡ãƒ»è¤‡å‹ç‡ã‚’è¨ˆç®— ---
        for idx, row in filtered_df.iterrows():
            total = int(row["1ç€"]) + int(row["2ç€"]) + int(row["3ç€"]) + int(row["ç€å¤–"])
            win_rate = (int(row["1ç€"]) / total) * 100 if total > 0 else 0.0
            fukusho_rate = ((int(row["1ç€"]) + int(row["2ç€"]) + int(row["3ç€"])) / total) * 100 if total > 0 else 0.0
            filtered_df.at[idx, "å‹ç‡"] = round(win_rate, 1)
            filtered_df.at[idx, "è¤‡å‹ç‡"] = round(fukusho_rate, 1)

        # --- åˆ—ã®ä¸¦ã³ã‚’æŒ‡å®šï¼ˆç€å¤–ã®æ¨ªã«å‹ç‡ãƒ»è¤‡å‹ç‡ã‚’è¿½åŠ ï¼‰---
        cols = ["ã‚¯ãƒ©ã‚¹", "è¡€çµ±", "1ç€", "2ç€", "3ç€", "ç€å¤–", "å‹ç‡", "è¤‡å‹ç‡"]
        filtered_df = filtered_df[cols]
    
    # â‘¡ è¿‘5èµ°
    recent5 = recent_5_performances(hid, date_str)

    # â‘¢ èŠ/ãƒ€ãƒ¼ãƒˆåˆ¥ã‚µãƒãƒª
    surface_summary = turf_dirt_summary(hid, date_str)

    # â‘£ åŒã‚³ãƒ¼ã‚¹ã®æŒã¡æ™‚è¨ˆï¼ˆã‚‚ã— race_type/course_len ä¸ãˆã‚‰ã‚Œã¦ã„ã‚Œã°ï¼‰
    same_course_best = None
    if race_type and course_len:
        same_course_best = same_course_best_time(hid, course_len, race_type, place_id, date_str)

    # combine
    return {
        "horse_name": horse_name,
        "horse_id": hid,
        "peds0": peds0,
        "place_id": place_id,
        "race_type" : race_type, 
        "course_len" : course_len, 
        "ground_state": ground_state, 
        "race_class" :race_class,
        "peds_results": filtered_df if (isinstance(filtered_df, pd.DataFrame) and not filtered_df.empty) else None,
        "recent5": recent5,
        "surface_summary": surface_summary,
        "same_course_best": same_course_best
    }

# ---- HTML æ•´å½¢ï¼ˆç°¡æ˜“ï¼‰ ----
def get_time_diff_color(diff_str):
    """
    å¹³å‡å‹ã¡æ™‚è¨ˆã¨ã®å·®ã§è‰²ã‚’è¿”ã™
    - ãƒã‚¤ãƒŠã‚¹ãªã‚‰èµ¤
    - 0.5ç§’ä»¥å†…ãªã‚‰ ã‚ªãƒ¬ãƒ³ã‚¸
    - ãã‚Œä»¥ä¸Šãªã‚‰ é»’
    """
    try:
        diff_str = str(diff_str).strip()
        if not diff_str or diff_str == "-":
            return "black"
        
        diff_str_clean = diff_str.replace("ç§’", "").strip()
        diff_val = float(diff_str_clean)
        
        if diff_val < 0:
            return "red"        # ãƒã‚¤ãƒŠã‚¹ = èµ¤ï¼ˆé€Ÿã„ï¼‰
        elif 0 <= diff_val <= 0.2:
            return "orange"     # 0.2ç§’ä»¥å†… = ã‚ªãƒ¬ãƒ³ã‚¸ï¼ˆã»ã¼åŒç­‰ï¼‰
        else:
            return "black"      # 0.2ç§’ä»¥ä¸Š = é»’ï¼ˆé…ã„ï¼‰
    except:
        return "black"

def get_class_color(class_name):
    """ã‚¯ãƒ©ã‚¹ã«åŸºã¥ã„ã¦èƒŒæ™¯è‰²ã‚’è¿”ã™"""
    class_colors = {
        "æœªå‹åˆ©": "#fff0f0",    # è–„èµ¤
        "æ–°é¦¬": "#ffe6e6",      # å°‘ã—æ¿ƒã„èµ¤
        "1å‹ã‚¯ãƒ©ã‚¹": "#ffcccc", # ã•ã‚‰ã«æ¿ƒã„èµ¤
        "2å‹ã‚¯ãƒ©ã‚¹": "#ffb3b3", # ã‚‚ã£ã¨æ¿ƒã„èµ¤
        "3å‹ã‚¯ãƒ©ã‚¹": "#ff9999", # ã•ã‚‰ã«æ¿ƒã„èµ¤
        "ã‚ªãƒ¼ãƒ—ãƒ³": "#ff8080"   # æ¿ƒã„èµ¤
    }
    return class_colors.get(class_name, "#ffffff")

def get_race_type_color(race_type):
    """ãƒ¬ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—ã«åŸºã¥ã„ã¦èƒŒæ™¯è‰²ã‚’è¿”ã™"""
    race_type_color = "#ffffff"
    if "ãƒ€" in race_type:
        race_type_color = "#D2691E"
    elif "èŠ" in race_type:
        race_type_color = "#32CD32"
    elif "éšœ" in race_type:
        race_type_color = "#8B4513"
    return race_type_color

def get_ground_state_color(ground_state):
    """é¦¬å ´çŠ¶æ…‹ã«åŸºã¥ã„ã¦èƒŒæ™¯è‰²ã‚’è¿”ã™"""
    ground_state_color = "#ffffff"
    if "ç¨" in ground_state:
        ground_state_color = "#e8e8e8"
    elif "é‡" in ground_state:
        ground_state_color = "#b0b0b0"
    elif "ä¸" in ground_state:
        ground_state_color = "#808080"
    return ground_state_color

def horse_report_to_html(report: Dict[str, Any]) -> str:
    """
    build_horse_report ã®å‡ºåŠ›ã‹ã‚‰ã‚¹ã‚¿ã‚¤ãƒ«ä»˜ãHTML ã‚’ä½œã‚‹ã€‚
    è‰²ä»˜ã‘ãƒ­ã‚¸ãƒƒã‚¯:
    - ç€é †ã€äººæ°—: 1ç€=é»„è‰²ã€2ç€=æ°´è‰²ã€3ç€=ã‚ªãƒ¬ãƒ³ã‚¸
    - å¹³å‡æ™‚è¨ˆã¨ã®å·®: ãƒã‚¤ãƒŠã‚¹=èµ¤ã€0.5ç§’ä»¥å†…=ã‚ªãƒ¬ãƒ³ã‚¸ã€ãã‚Œä»¥ä¸Š=é»’
    - ã‚¯ãƒ©ã‚¹: æœªå‹åˆ©â†’æ–°é¦¬â†’1å‹â†’2å‹â†’3å‹â†’ã‚ªãƒ¼ãƒ—ãƒ³ã§è‰²ãŒæ¿ƒããªã‚‹
    - æ ç•ªãƒ»é¦¬ç•ª: æ•°å­—ã®ã¿ã«è‰²ä»˜ã‘
    """
    if "error" in report:
        return f"<div class='horse-report error'>{report['error']}</div>"

    html = []
    html.append("<div class='horse-report' style='padding: 10px; background: #fafafa; border: 1px solid #ddd;'>")

    # PEDs
    p = report.get("peds0", {})
    if p:
        html.append(f"<h4>è¡€çµ± (çˆ¶) : <strong>{p}</strong></h4>")
    else:
        html.append("<h4>è¡€çµ± (çˆ¶) : - </h4>")
    
    race_type =  report.get("race_type", "-")
    course_len =  report.get("course_len", "-")
    ground_state =  report.get("ground_state", "-")
    place_id =  report.get("place_id", "-")
    place_num = name_header.NAME_LIST[place_id - 1]
    # PedsResultsï¼ˆsummaryï¼‰
    pr = report.get("peds_results")
    if pr is None or (isinstance(pr, pd.DataFrame) and pr.empty):
        html.append("<div>è¡€çµ±ãƒ‡ãƒ¼ã‚¿ãªã—</div>")
    else:
        html.append(f"<h4>ğŸ§¬ {place_num} {race_type}{course_len}m ({ground_state})</h4>")
        html.append("<table style='width:100%; border-collapse: collapse; text-align: center;'>")
        html.append("<thead><tr style='background:#f2f2f2;'><th>ã‚¯ãƒ©ã‚¹</th><th>è¡€çµ±</th><th>1ç€</th><th>2ç€</th><th>3ç€</th><th>ç€å¤–</th><th>å‹ç‡</th><th>è¤‡å‹ç‡</th></tr></thead><tbody>")
        
        for _, row in pr.iterrows():
            class_name = row.get("ã‚¯ãƒ©ã‚¹", "")
            html.append(f"<td><strong>{class_name}</strong></td>")
            html.append(f"<td>{extract_peds_name(row.get('è¡€çµ±', '-'))}</td>")
            html.append(f"<td>{row.get('1ç€', '-')}</td>")
            html.append(f"<td>{row.get('2ç€', '-')}</td>")
            html.append(f"<td>{row.get('3ç€', '-')}</td>")
            html.append(f"<td>{row.get('ç€å¤–', '-')}</td>")
            html.append(f"<td>{row.get('å‹ç‡', '-')}</td>")
            html.append(f"<td>{row.get('è¤‡å‹ç‡', '-')}</td>")
            html.append("</tr>")
        
        html.append("</tbody></table>")

    # recent5
    html.append("<h4>ğŸ“Š è¿‘5èµ°æˆç¸¾</h4>")
    if report.get("recent5"):
        html.append("<table style='width:100%; border-collapse: collapse; text-align: center; font-size: 12px;'>")
        html.append("<thead><tr style='background:#f2f2f2;'><th>æ—¥ä»˜</th><th>é–‹å‚¬</th><th>R</th><th>ãƒ¬ãƒ¼ã‚¹å</th><th>ã‚¯ãƒ©ã‚¹</th><th>ç€é †</th><th>äººæ°—</th><th>æ </th><th>é¦¬ç•ª</th><th>ç¨®åˆ¥</th><th>è·é›¢</th><th>é¦¬å ´</th><th>ã‚¿ã‚¤ãƒ </th><th>ç€å·®</th><th>å¹³å‡æ™‚è¨ˆã¨ã®å·®</th><th>ä¸Šã‚Š</th><th>é€šé</th><th>é¦¬ä½“é‡</th></tr></thead><tbody>")
        
        for r in report["recent5"]:
            # ç€é †ã®è‰²ä»˜ã‘
            finish = r.get("result", "-")
            finish_color =  RANK_COLORS.get(finish, "#ffffff")
            finish_html = f'<td style="background-color: {finish_color}; font-weight: bold;">{finish}</td>'
            
            # äººæ°—ã®è‰²ä»˜ã‘
            popularity = str(r.get("pops", "-"))
            pop_color = RANK_COLORS.get(popularity, "#ffffff")
            pop_html = f'<td style="background-color: {pop_color}; font-weight: bold;">{popularity}</td>'
            
            # å¹³å‡æ™‚è¨ˆã¨ã®å·®ã®è‰²ä»˜ã‘
            diff_avg = r.get("diff_avg_ms", "-")
            diff_color = get_time_diff_color(diff_avg)
            diff_html = f'<td style="color: {diff_color}; font-weight: bold;">{diff_avg}</td>'
            
            # æ ç•ªãƒ»é¦¬ç•ªã®è‰²ä»˜ã‘
            waku = r.get("waku", "-")
            umaban = r.get("umaban", "-")
            waku_color = WAKU_COLORS.get(waku, "#ffffff")
            waku_html = f'<td style="background-color:{waku_color}; color:{"#fff" if waku in ["2","3","4","7"] else "#000"};">{waku}</td>'
            umaban_html =  f'<td style="background-color:{waku_color}; color:{"#fff" if waku in ["2","3","4","7"] else "#000"};">{umaban}</td>'

            # ã‚¯ãƒ©ã‚¹ã®è‰²ä»˜ã‘
            class_name = r.get("class_name", "")
            class_bg_color = get_class_color(class_name)
            class_html = f'<td style="background-color:{class_bg_color}; padding: 2px 4px; border-radius: 3px;">{class_name}</td>'
            
            # ãƒ¬ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—ã®è‰²ä»˜ã‘
            recent_race_type = r.get('race_type', '-')
            race_type_color = get_race_type_color(recent_race_type)
            race_type_html = f'<td style="background-color:{race_type_color};font-weight: bold;">{recent_race_type}</td>'
            rescent_course_len = r.get('course', '-')
            course_html = f'<td style="background-color:{race_type_color}; font-weight: bold;">{rescent_course_len}</td>'

            # é¦¬å ´çŠ¶æ…‹ã®è‰²ä»˜ã‘
            ground_state = r.get('ground', '-')
            ground_state_color = get_ground_state_color(ground_state)
            ground_state_html = f'<td style="background-color:{ground_state_color};">{ground_state}</td>'


            html.append("<tr>")
            html.append(f"<td>{r.get('date', '-')}</td>")
            html.append(f"<td>{r.get('course_name', '-')}</td>")
            html.append(f"<td>{r.get('race_num', '-')}</td>")
            html.append(f"<td>{r.get('race_name', '-')}</td>")
            html.append(f"{class_html}")
            html.append(f"{finish_html}")
            html.append(f"{pop_html}")
            html.append(f"{waku_html}")
            html.append(f"{umaban_html}")
            html.append(f"{race_type_html}")
            html.append(f"{course_html}")
            html.append(f"{ground_state_html}")
            html.append(f"<td>{r.get('time_raw', '-')}</td>")
            html.append(f"<td>{r.get('diff_ms', '-')}</td>")
            html.append(f"{diff_html}")
            html.append(f"<td>{r.get('ä¸Šã‚Š', '-')}</td>")
            html.append(f"<td>{r.get('é€šé', '-')}</td>")
            html.append(f"<td>{r.get('é¦¬ä½“é‡', '-')}</td>")
            html.append("</tr>")
        
        html.append("</tbody></table>")
    else:
        html.append("<div>ç›´è¿‘5èµ°ãƒ‡ãƒ¼ã‚¿ãªã—</div>")

    # surface summary
    html.append("<h4>ğŸ‡ èŠ/ãƒ€ãƒ¼ãƒˆã‚µãƒãƒª</h4>")
    html.append("""
    <table border="1" style="border-collapse:collapse; text-align:center;">
    <thead>
        <tr>
        <th>ã‚³ãƒ¼ã‚¹</th>
        <th>æœ€é€Ÿä¸Šã‚Š</th>
        <th>å¹³å‡ä¸Šã‚Š</th>
        <th>å¹³å‡é€šéä½ç½®</th>
        <th>å¯¾è±¡ãƒ¬ãƒ¼ã‚¹æ•°</th>
        </tr>
    </thead>
    <tbody>
    """)

    for surf in ["èŠ", "ãƒ€ãƒ¼ãƒˆ"]:
        s = report.get("surface_summary", {}).get(surf, {})
        if s:
            fastest_up = s.get("fastest_up")
            fastest_info = s.get("fastest_up_info", {})
            fastest_text = "-"
            if fastest_up:
                fastest_text = f"<strong>{fastest_up}</strong> <br> {fastest_info.get('date', '-')}: {fastest_info.get('race_name', '-')} ({fastest_info.get('course_name', '-')} {fastest_info.get('course_len', '-')}m {fastest_info.get('é¦¬å ´', '-')})"
            
            html.append(f"""
            <tr>
            <td>{surf}</td>
            <td>{fastest_text}</td>
            <td><strong>{safe_value(s.get('avg_up', '-'))}</strong></td>
            <td>{safe_value(s.get('avg_pass_norm', '-'))}</td>
            <td>{s.get('count', '-')}</td>
            </tr>
            """)
        else:
            html.append(f"""
            <tr>
            <td>{surf}</td>
            <td colspan="4">ãƒ‡ãƒ¼ã‚¿ãªã—</td>
            </tr>
            """)

    html.append("</tbody></table>")

    # same course best
    scb = report.get("same_course_best")
    html.append(f"<h4>â±ï¸ {place_num} {race_type}{course_len}m æŒã¡æ™‚è¨ˆ</h4>")
    if scb:
        html.append("<ul>")
        html.append(f"<li>{scb.get('date', '-')}: {scb.get('race_name', '-')} </li>")
        html.append(f"<li>ã‚¿ã‚¤ãƒ : <strong>{scb.get('time_str', '-')}</strong>(é¦¬å ´: {scb.get('ground', '-')})</li>")
        html.append("</ul>")
    else:
        html.append("<div>åŒã‚³ãƒ¼ã‚¹å‡ºèµ°ãƒ‡ãƒ¼ã‚¿ãªã—</div>")

    html.append("</div>")
    return "\n".join(html)

# ---- ä½¿ã„æ–¹ä¾‹ ----
if __name__ == "__main__":
    # ä¾‹: raceãƒšãƒ¼ã‚¸ã§ã€Œã‚µãƒˆãƒã‚·ãƒ£ãƒ ãƒ­ãƒƒã‚¯ã€ã‚’å‡¦ç†ã™ã‚‹å ´åˆ
    # place_name ã¨ condition_file ã¯å‘¼ã³å‡ºã—å´ã®å‘½åè¦å‰‡ã«åˆã‚ã›ã¦æŒ‡å®š
    place_id = 8
    horse_name = "ã‚·ãƒ¥ãƒãƒ«ãƒ„ãƒã‚µãƒ ãƒ"
    race_id ="202508030610"
    dates_str = "20251018"
    # race_type/course_len ã‚’ä¸ãˆã‚‹ã¨åŒã‚³ãƒ¼ã‚¹ã®æŒã¡æ™‚è¨ˆã‚‚æ¢ã™
    report = build_horse_report(horse_name, place_id, race_id, dates_str)
    print(report)
    # html = horse_report_to_html(report)
    # print(html)  # å…ˆé ­ã ã‘ç¢ºèª