import os
import sys
import re

from datetime import date
from glob import glob
import pandas as pd
import numpy as np
import warnings
warnings.simplefilter('ignore')

sys.dont_write_bytecode = True
sys.path.append(r"C:\keiba_ai\keiba_ai_ver2.0\libs")
import name_header

# # --- å›ºå®šãƒªã‚¹ãƒˆ ---
CLASSES = ["all", "æœªå‹åˆ©","æ–°é¦¬", "1å‹ã‚¯ãƒ©ã‚¹", "2å‹ã‚¯ãƒ©ã‚¹", "3å‹ã‚¯ãƒ©ã‚¹", "ã‚ªãƒ¼ãƒ—ãƒ³"]
GROUNDS = ["å…¨", "è‰¯", "ç¨é‡", "é‡", "ä¸è‰¯"]

def analyze_winner_weights_multi_years(base_dir, place_id, start_year):
    """
    å„å¹´åº¦ï¼ˆstart_yearã€œä»Šå¹´ï¼‰ã«ã¤ã„ã¦å‹ã¡é¦¬ã®å¹³å‡é¦¬ä½“é‡ã‚’ç®—å‡ºã—ã€
    å¹´ã”ã¨ã®çµæœ + å…¨æœŸé–“å¹³å‡ã® DataFrame ã‚’è¿”ã™ã€‚

    Parameters
    ----------
    base_dir : str
        CSV ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹ï¼ˆä¾‹: "./data/"ï¼‰
        â†’ ãƒ•ã‚¡ã‚¤ãƒ«åã¯ "{year}_race_results.csv" ã®ã‚ˆã†ã«ã™ã‚‹å‰æã€‚
    place_id : int
        ç«¶é¦¬å ´ID (1ã€œ10)
    start_year : int
        é›†è¨ˆã‚’å§‹ã‚ã‚‹å¹´ï¼ˆä¾‹: 2020ï¼‰

    Returns
    -------
    results_by_year : dict[int, pd.DataFrame]
        å¹´åº¦åˆ¥ã®çµæœã‚’æ ¼ç´ã—ãŸè¾æ›¸ã€‚
    total_df : pd.DataFrame
        å…¨æœŸé–“ã®å¹³å‡çµæœã€‚
    """
    current_year = int(date.today().year)
    results_by_year = {}

    for year in range(start_year, current_year + 1):
        csv_path = os.path.join(base_dir, f"{year}_race_results.csv")
        if not os.path.exists(csv_path):
            print(f"âš ï¸ {csv_path} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
            continue
        print(f"ğŸ“˜ {year}å¹´ã®ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ä¸­ ...")
        df_year = analyze_winner_weights(csv_path, place_id)
        if not df_year.empty:
            df_year["year"] = year
            results_by_year[year] = df_year

    if not results_by_year:
        print("âŒ æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return {}, pd.DataFrame()

    combined_df = pd.concat(results_by_year.values(), ignore_index=True)

    group_cols = ["race_type", "course_len", "ground_state", "class"]
    total_df = (
        combined_df.groupby(group_cols, dropna=False)["é¦¬ä½“é‡"]
        .mean()
        .round(1)
        .reset_index()
    )

    total_df["race_type"] = pd.Categorical(total_df["race_type"], categories=["èŠ", "ãƒ€ãƒ¼ãƒˆ"], ordered=True)
    total_df["class"] = pd.Categorical(total_df["class"], categories=CLASSES, ordered=True)
    total_df["ground_state"] = pd.Categorical(total_df["ground_state"], categories=GROUNDS, ordered=True)
    total_df = total_df.sort_values(["race_type", "course_len", "class", "ground_state"]).reset_index(drop=True)
    total_df = total_df.reindex(columns=["race_type", "course_len", "ground_state", "class", "é¦¬ä½“é‡"])

    print(f"âœ… å…¨æœŸé–“å¹³å‡ï¼ˆ{start_year}ã€œ{current_year}ï¼‰ã‚’ä½œæˆã—ã¾ã—ãŸã€‚")
    return total_df 

def analyze_winner_weights(csv_path, place_id):
    """
    å‹ã¡é¦¬ã®ã€Œé¦¬ä½“é‡ã€å¹³å‡ã‚’ race_type, course_len, ground_state, class ã”ã¨ã«ç®—å‡ºã™ã‚‹ã€‚
    """
    if os.path.isfile(csv_path):
        df_raw = pd.read_csv(csv_path, dtype=str, index_col=0).reset_index().rename(columns={"index": "race_id"})
    else:
        return pd.DataFrame()

    df = df_raw.copy()
    df["ç€é †"] = pd.to_numeric(df["ç€é †"], errors="coerce")
    df["course_len"] = pd.to_numeric(df["course_len"], errors="coerce")
    df["é¦¬ä½“é‡"] = pd.to_numeric(df["é¦¬ä½“é‡"], errors="coerce")

    winners = df[df["ç€é †"] == 1].copy()
    if winners.empty:
        return pd.DataFrame()

    all_results = []
    courses = name_header.COURSE_LISTS[place_id - 1]

    for race_type, course_len in courses:
        base_data = winners[
            (winners["race_type"] == race_type) &
            (winners["course_len"] == float(course_len))
        ]

        for cls in CLASSES:
            for grd in GROUNDS:
                tmp = base_data.copy()
                if cls != "all":
                    tmp = tmp[tmp["class"] == cls]
                if grd != "å…¨":
                    tmp = tmp[tmp["ground_state"] == grd]

                avg_weight = tmp["é¦¬ä½“é‡"].mean() if not tmp.empty else None

                all_results.append({
                    "race_type": race_type,
                    "course_len": int(course_len),
                    "ground_state": grd,
                    "class": cls,
                    "é¦¬ä½“é‡": round(avg_weight, 1) if avg_weight is not None else None,
                })

    df_result = pd.DataFrame(all_results).round(1)
    df_result["race_type"] = pd.Categorical(df_result["race_type"], categories=["èŠ", "ãƒ€ãƒ¼ãƒˆ"], ordered=True)
    df_result["class"] = pd.Categorical(df_result["class"], categories=CLASSES, ordered=True)
    df_result["ground_state"] = pd.Categorical(df_result["ground_state"], categories=GROUNDS, ordered=True)
    df_result = df_result.sort_values(["race_type", "course_len", "class", "ground_state"]).reset_index(drop=True)

    df_result = df_result.reindex(columns=["race_type", "course_len", "ground_state", "class", "é¦¬ä½“é‡"])

    return df_result

def analyze_average_pops_multi_years(base_dir, place_id, start_year):
    """
    å„å¹´åº¦ï¼ˆstart_yearã€œä»Šå¹´ï¼‰ã«ã¤ã„ã¦ã€äººæ°—ã®å¹³å‡ã‚’æ­£è¦åŒ–ã—ã¦ç®—å‡ºã—ã€
    å¹´ã”ã¨ã®çµæœ + å…¨æœŸé–“å¹³å‡ã® DataFrame ã‚’è¿”ã™ã€‚
    """
    current_year = int(date.today().year)
    results_by_year = {}

    for year in range(start_year, current_year + 1):
        csv_path = os.path.join(base_dir, f"{year}_race_results.csv")
        if not os.path.exists(csv_path):
            print(f"âš ï¸ {csv_path} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
            continue

        print(f"ğŸ“˜ {year}å¹´ã®äººæ°—ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ä¸­ ...")
        df_year = analyze_average_pops(csv_path, place_id)
        if not df_year.empty:
            df_year["year"] = year
            results_by_year[year] = df_year

    if not results_by_year:
        print("âŒ æœ‰åŠ¹ãªäººæ°—ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return {}, pd.DataFrame()

    combined_df = pd.concat(results_by_year.values(), ignore_index=True)

    group_cols = ["race_type", "course_len", "ground_state", "class"]
    total_df = (
        combined_df.groupby(group_cols, dropna=False)[["winner_pops", "place_pops"]]
        .mean()
        .round(2)
        .reset_index()
    )

    total_df["race_type"] = pd.Categorical(total_df["race_type"], categories=["èŠ", "ãƒ€ãƒ¼ãƒˆ"], ordered=True)
    total_df["class"] = pd.Categorical(total_df["class"], categories=CLASSES, ordered=True)
    total_df["ground_state"] = pd.Categorical(total_df["ground_state"], categories=GROUNDS, ordered=True)

    total_df = total_df.sort_values(["race_type", "course_len", "class", "ground_state"]).reset_index(drop=True)
    total_df = total_df.reindex(columns=["race_type", "course_len", "ground_state", "class", "winner_pops", "place_pops"])

    print(f"âœ… å…¨æœŸé–“å¹³å‡ï¼ˆ{start_year}ã€œ{current_year}ï¼‰ã‚’ä½œæˆã—ã¾ã—ãŸã€‚")
    return total_df


def analyze_average_pops(csv_path, place_id):
    """
    å‹ã¡é¦¬ãƒ»3ç€ä»¥å†…é¦¬ã®å¹³å‡äººæ°—ã‚’ race_type, course_len, ground_state, class ã”ã¨ã«ç®—å‡ºã™ã‚‹ã€‚
    é ­æ•°ã«ã‚ˆã‚‹æ­£è¦åŒ–ã‚ã‚Šï¼ˆ18é ­ç«‹ã¦æ›ç®—ï¼‰ã€‚
    """
    if os.path.isfile(csv_path):
        df_raw = pd.read_csv(csv_path, dtype=str, index_col=0).reset_index().rename(columns={"index": "race_id"})
    else:
        return pd.DataFrame()

    df = df_raw.copy()
    df["ç€é †"] = pd.to_numeric(df["ç€é †"], errors="coerce")
    df["äººæ°—"] = pd.to_numeric(df["äººæ°—"], errors="coerce")
    df["course_len"] = pd.to_numeric(df["course_len"], errors="coerce")

    # å‡ºèµ°é ­æ•°ã‚’ç®—å‡ºï¼ˆrace_idå˜ä½ï¼‰
    df["é ­æ•°"] = df.groupby("race_id")["é¦¬ç•ª"].transform("count")

    all_results = []
    courses = name_header.COURSE_LISTS[place_id - 1]

    for race_type, course_len in courses:
        base_data = df[
            (df["race_type"] == race_type) &
            (df["course_len"] == float(course_len))
        ]

        for cls in CLASSES:
            for grd in GROUNDS:
                tmp = base_data.copy()
                if cls != "all":
                    tmp = tmp[tmp["class"] == cls]
                if grd != "å…¨":
                    tmp = tmp[tmp["ground_state"] == grd]

                if tmp.empty:
                    all_results.append({
                        "race_type": race_type,
                        "course_len": int(course_len),
                        "ground_state": grd,
                        "class": cls,
                        "winner_pops": None,
                        "place_pops": None
                    })
                    continue

                # --- å‹ã¡é¦¬ãƒ‡ãƒ¼ã‚¿ ---
                winners = tmp[tmp["ç€é †"] == 1].copy()
                winners["norm_pop"] = winners["äººæ°—"] * (18 / winners["é ­æ•°"])
                avg_winner = winners["norm_pop"].mean() if not winners.empty else None

                # --- 3ç€ä»¥å†…ãƒ‡ãƒ¼ã‚¿ ---
                places = tmp[tmp["ç€é †"].isin([1, 2, 3])].copy()
                places["norm_pop"] = places["äººæ°—"] * (18 / places["é ­æ•°"])
                avg_place = places["norm_pop"].mean() if not places.empty else None

                all_results.append({
                    "race_type": race_type,
                    "course_len": int(course_len),
                    "ground_state": grd,
                    "class": cls,
                    "winner_pops": round(avg_winner, 2) if avg_winner else None,
                    "place_pops": round(avg_place, 2) if avg_place else None
                })

    df_result = pd.DataFrame(all_results)
    df_result["race_type"] = pd.Categorical(df_result["race_type"], categories=["èŠ", "ãƒ€ãƒ¼ãƒˆ"], ordered=True)
    df_result["class"] = pd.Categorical(df_result["class"], categories=CLASSES, ordered=True)
    df_result["ground_state"] = pd.Categorical(df_result["ground_state"], categories=GROUNDS, ordered=True)
    df_result = df_result.sort_values(["race_type", "course_len", "class", "ground_state"]).reset_index(drop=True)
    df_result = df_result.reindex(columns=["race_type", "course_len", "ground_state", "class", "winner_pops", "place_pops"])

    return df_result

def update_horse_name_id_map(place_id, year):
    """
    æŒ‡å®šãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®ãƒ¬ãƒ¼ã‚¹çµæœCSVã‚’ã™ã¹ã¦èª­ã¿è¾¼ã¿ã€
    æ—¢å­˜ã® horse_name_id_map.csv ã«ãƒãƒ¼ã‚¸ã—ã¦æ›´æ–°ã™ã‚‹ã€‚

    Parameters
    ----------
    input_dir : str
        ãƒ¬ãƒ¼ã‚¹çµæœCSVã®æ ¼ç´ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆä¾‹: './RaceResults/'ï¼‰
    output_path : str
        å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆä¾‹: './horse_name_id_map.csv'ï¼‰
    """
    csv_file_path = os.path.join(name_header.DATA_PATH, "horse_id_map.csv")
    # --- æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ ---
    if os.path.exists(csv_file_path):
        existing_df = pd.read_csv(csv_file_path, dtype=str)
        print(f"ğŸ“˜ æ—¢å­˜ã®å¯¾å¿œè¡¨ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ ({len(existing_df)}ä»¶)")
    else:
        existing_df = pd.DataFrame(columns=["é¦¬å", "horse_id"])
        print("âš ï¸ æ—¢å­˜ã®å¯¾å¿œè¡¨ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚æ–°è¦ä½œæˆã—ã¾ã™ã€‚")

    # --- æ–°è¦ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ ---
    input_files = os.path.join(name_header.DATA_PATH, "RaceResults", name_header.PLACE_LIST[place_id - 1], f"{year}_race_results.csv")

    # --- å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ ---
    print()
    all_data = []
    if not os.path.exists(input_files):
        print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {input_files}")
    else:
        try:
            df = pd.read_csv(input_files, dtype=str)
            if "é¦¬å" in df.columns and "horse_id" in df.columns:
                all_data.append(df[["é¦¬å", "horse_id"]].dropna())
                print(f"ğŸ“— èª­ã¿è¾¼ã¿æˆåŠŸ: {input_files} ({len(df)}ä»¶)")
            else:
                print(f"âš ï¸ ã‚«ãƒ©ãƒ ä¸è¶³ã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—: {input_files}")
        except Exception as e:
            print(f"[WARN] {input_files} èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")

    if not all_data:
        print("âŒ æœ‰åŠ¹ãªCSVãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

     # --- çµåˆ ---
    new_df = pd.concat(all_data, ignore_index=True)
    merged_df = pd.concat([existing_df, new_df], ignore_index=True)

    # --- é‡è¤‡å‰Šé™¤ ---
    merged_df = merged_df.drop_duplicates(subset=["horse_id"], keep="first")
    merged_df = merged_df.drop_duplicates(subset=["é¦¬å"], keep="first")

    # --- horse_idé †ã«ã‚½ãƒ¼ãƒˆ ---
    merged_df = merged_df.sort_values(by="horse_id").reset_index(drop=True)

    # --- ä¿å­˜ ---
    merged_df.to_csv(csv_file_path, index=False, encoding="utf-8-sig")

    print(f"âœ… é¦¬åãƒ»horse_idå¯¾å¿œè¡¨ã‚’æ›´æ–°ã—ã¾ã—ãŸ ({len(merged_df)}ä»¶): {csv_file_path}")

if __name__ == '__main__':
    # for place_id in range(1, len(name_header.PLACE_LIST) + 1):
    #     for year in range(2019, 2026):
    #         update_horse_name_id_map(place_id,year)

    for place_id in range(1, len(name_header.PLACE_LIST) + 1):
        # å„å¹´ã®è¨˜éŒ²ã‚’è¨ˆç®—
        for year in range(2019,date.today().year + 1):
            csv_path = name_header.DATA_PATH + "//RaceResults//" + name_header.PLACE_LIST[place_id -1] + "//" + f"{year}_race_results.csv"
            result = analyze_average_pops(csv_path, place_id)
            if not result.empty:
                output_path = name_header.DATA_PATH + "//AveragePops//" + name_header.PLACE_LIST[place_id -1] + "//" + f"{year}_average_pops.csv"
                result.to_csv(output_path)
        # totalã®è¨˜éŒ²ã‚’è¨ˆç®—
        base_dir = name_header.DATA_PATH + "//RaceResults//" + name_header.PLACE_LIST[place_id -1] + "//"
        total_df = analyze_average_pops_multi_years(base_dir, place_id, 2019)
        total_ouutput_path = name_header.DATA_PATH + "//AveragePops//" + name_header.PLACE_LIST[place_id -1] + "//" + "total_average_pops.csv"
        total_df.to_csv(total_ouutput_path)