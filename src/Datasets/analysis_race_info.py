import os
import sys
import re

from datetime import date
from glob import glob
import pandas as pd
import numpy as np
import warnings
warnings.simplefilter('ignore')

sys.dont_write_bytecode = True
sys.path.append(r"C:\keiba_ai\keiba_ai_ver2.0\libs")
import name_header

# # --- å›ºå®šãƒªã‚¹ãƒˆ ---
CLASSES = ["all", "æœªå‹åˆ©","æ–°é¦¬", "1å‹ã‚¯ãƒ©ã‚¹", "2å‹ã‚¯ãƒ©ã‚¹", "3å‹ã‚¯ãƒ©ã‚¹", "ã‚ªãƒ¼ãƒ—ãƒ³"]
GROUNDS = ["å…¨", "è‰¯", "ç¨é‡", "é‡", "ä¸è‰¯"]

def analyze_winner_weights_multi_years(base_dir, place_id, start_year):
    """
    å„å¹´åº¦ï¼ˆstart_yearã€œä»Šå¹´ï¼‰ã«ã¤ã„ã¦å‹ã¡é¦¬ã®å¹³å‡é¦¬ä½“é‡ã‚’ç®—å‡ºã—ã€
    å¹´ã”ã¨ã®çµæœ + å…¨æœŸé–“å¹³å‡ã® DataFrame ã‚’è¿”ã™ã€‚

    Parameters
    ----------
    base_dir : str
        CSV ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹ï¼ˆä¾‹: "./data/"ï¼‰
        â†’ ãƒ•ã‚¡ã‚¤ãƒ«åã¯ "{year}_race_results.csv" ã®ã‚ˆã†ã«ã™ã‚‹å‰æã€‚
    place_id : int
        ç«¶é¦¬å ´ID (1ã€œ10)
    start_year : int
        é›†è¨ˆã‚’å§‹ã‚ã‚‹å¹´ï¼ˆä¾‹: 2020ï¼‰

    Returns
    -------
    results_by_year : dict[int, pd.DataFrame]
        å¹´åº¦åˆ¥ã®çµæœã‚’æ ¼ç´ã—ãŸè¾æ›¸ã€‚
    total_df : pd.DataFrame
        å…¨æœŸé–“ã®å¹³å‡çµæœã€‚
    """
    current_year = int(date.today().year)
    results_by_year = {}

    for year in range(start_year, current_year + 1):
        csv_path = os.path.join(base_dir, f"{year}_race_results.csv")
        if not os.path.exists(csv_path):
            print(f"âš ï¸ {csv_path} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
            continue
        print(f"ğŸ“˜ {year}å¹´ã®ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ä¸­ ...")
        df_year = analyze_winner_weights(csv_path, place_id)
        if not df_year.empty:
            df_year["year"] = year
            results_by_year[year] = df_year

    if not results_by_year:
        print("âŒ æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return {}, pd.DataFrame()

    combined_df = pd.concat(results_by_year.values(), ignore_index=True)

    group_cols = ["race_type", "course_len", "ground_state", "class"]
    total_df = (
        combined_df.groupby(group_cols, dropna=False)["é¦¬ä½“é‡"]
        .mean()
        .round(1)
        .reset_index()
    )

    total_df["race_type"] = pd.Categorical(total_df["race_type"], categories=["èŠ", "ãƒ€ãƒ¼ãƒˆ"], ordered=True)
    total_df["class"] = pd.Categorical(total_df["class"], categories=CLASSES, ordered=True)
    total_df["ground_state"] = pd.Categorical(total_df["ground_state"], categories=GROUNDS, ordered=True)
    total_df = total_df.sort_values(["race_type", "course_len", "class", "ground_state"]).reset_index(drop=True)
    total_df = total_df.reindex(columns=["race_type", "course_len", "ground_state", "class", "é¦¬ä½“é‡"])

    print(f"âœ… å…¨æœŸé–“å¹³å‡ï¼ˆ{start_year}ã€œ{current_year}ï¼‰ã‚’ä½œæˆã—ã¾ã—ãŸã€‚")
    return total_df 

def analyze_winner_weights(csv_path, place_id):
    """
    å‹ã¡é¦¬ã®ã€Œé¦¬ä½“é‡ã€å¹³å‡ã‚’ race_type, course_len, ground_state, class ã”ã¨ã«ç®—å‡ºã™ã‚‹ã€‚
    """
    if os.path.isfile(csv_path):
        df_raw = pd.read_csv(csv_path, dtype=str, index_col=0).reset_index().rename(columns={"index": "race_id"})
    else:
        return pd.DataFrame()

    df = df_raw.copy()
    df["ç€é †"] = pd.to_numeric(df["ç€é †"], errors="coerce")
    df["course_len"] = pd.to_numeric(df["course_len"], errors="coerce")
    df["é¦¬ä½“é‡"] = pd.to_numeric(df["é¦¬ä½“é‡"], errors="coerce")

    winners = df[df["ç€é †"] == 1].copy()
    if winners.empty:
        return pd.DataFrame()

    all_results = []
    courses = name_header.COURSE_LISTS[place_id - 1]

    for race_type, course_len in courses:
        base_data = winners[
            (winners["race_type"] == race_type) &
            (winners["course_len"] == float(course_len))
        ]

        for cls in CLASSES:
            for grd in GROUNDS:
                tmp = base_data.copy()
                if cls != "all":
                    tmp = tmp[tmp["class"] == cls]
                if grd != "å…¨":
                    tmp = tmp[tmp["ground_state"] == grd]

                avg_weight = tmp["é¦¬ä½“é‡"].mean() if not tmp.empty else None

                all_results.append({
                    "race_type": race_type,
                    "course_len": int(course_len),
                    "ground_state": grd,
                    "class": cls,
                    "é¦¬ä½“é‡": round(avg_weight, 1) if avg_weight is not None else None,
                })

    df_result = pd.DataFrame(all_results).round(1)
    df_result["race_type"] = pd.Categorical(df_result["race_type"], categories=["èŠ", "ãƒ€ãƒ¼ãƒˆ"], ordered=True)
    df_result["class"] = pd.Categorical(df_result["class"], categories=CLASSES, ordered=True)
    df_result["ground_state"] = pd.Categorical(df_result["ground_state"], categories=GROUNDS, ordered=True)
    df_result = df_result.sort_values(["race_type", "course_len", "class", "ground_state"]).reset_index(drop=True)

    df_result = df_result.reindex(columns=["race_type", "course_len", "ground_state", "class", "é¦¬ä½“é‡"])

    return df_result

def analyze_average_pop_multi_years(base_dir, place_id, start_year, top3=False):
    """
    å„å¹´åº¦ï¼ˆstart_yearã€œä»Šå¹´ï¼‰ã«ã¤ã„ã¦ã€äººæ°—ãƒ‡ãƒ¼ã‚¿ã‚’é›†è¨ˆã€‚
    å‹ã¡é¦¬ï¼ˆtop3=Falseï¼‰ã¾ãŸã¯3ç€å†…ï¼ˆtop3=Trueï¼‰ã‚’å¯¾è±¡ã«ã€
    å…¨æœŸé–“å¹³å‡ï¼ˆTOTALï¼‰ã‚’è¨ˆç®—ã—ã¦è¿”ã™ã€‚
    """
    current_year = int(date.today().year)
    results_by_year = {}

    for year in range(start_year, current_year + 1):
        csv_path = os.path.join(base_dir, f"{year}_race_results.csv")
        if not os.path.exists(csv_path):
            print(f"âš ï¸ {csv_path} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
            continue

        print(f"ğŸ“˜ {year}å¹´ã®äººæ°—ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ä¸­ ...")
        df_year = analyze_average_pops(csv_path, place_id, top3=top3)
        if not df_year.empty:
            df_year["year"] = year
            results_by_year[year] = df_year

    if not results_by_year:
        print("âŒ æœ‰åŠ¹ãªäººæ°—ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return {}, pd.DataFrame()

    # --- å…¨æœŸé–“çµåˆ ---
    combined_df = pd.concat(results_by_year.values(), ignore_index=True)

    # --- å¹³å‡å€¤ï¼†åˆè¨ˆã‚’é›†è¨ˆ ---
    group_cols = ["race_type", "course_len", "ground_state", "class"]

    # å¹³å‡äººæ°—
    avg_df = (
        combined_df.groupby(group_cols, dropna=False)["avg_pop"]
        .mean()
        .round(2)
        .reset_index()
    )

    # äººæ°—åˆ¥å‹åˆ©æ•°ã®åˆè¨ˆ
    pop_cols = [f"pop_{i}_count" for i in range(1, 19)]
    sum_df = (
        combined_df.groupby(group_cols, dropna=False)[pop_cols]
        .sum()
        .reset_index()
    )

    # çµåˆ
    total_df = pd.merge(avg_df, sum_df, on=group_cols, how="left")

    # --- ä¸¦ã³é †ã‚’æ•´ãˆã‚‹ ---
    total_df["race_type"] = pd.Categorical(total_df["race_type"], categories=["èŠ", "ãƒ€ãƒ¼ãƒˆ"], ordered=True)
    total_df["class"] = pd.Categorical(total_df["class"], categories=CLASSES, ordered=True)
    total_df["ground_state"] = pd.Categorical(total_df["ground_state"], categories=GROUNDS, ordered=True)

    total_df = total_df.sort_values(["race_type", "course_len", "class", "ground_state"]).reset_index(drop=True)
    total_df = total_df.reindex(columns=group_cols + ["avg_pop"] + pop_cols)

    print(f"âœ… å…¨æœŸé–“å¹³å‡ï¼ˆ{start_year}ã€œ{current_year}ï¼‰ã‚’ä½œæˆã—ã¾ã—ãŸã€‚å¯¾è±¡: {'3ç€å†…' if top3 else 'å‹ã¡é¦¬'}")
    return total_df


def analyze_average_pops(csv_path, place_id, top3=False):
    """
    å‹ã¡é¦¬ã¾ãŸã¯3ç€å†…é¦¬ã®å¹³å‡äººæ°—ã¨äººæ°—åˆ¥å‹åˆ©æ•°ã‚’é›†è¨ˆã€‚
    top3=True ã®å ´åˆã¯3ç€å†…ã‚’å¯¾è±¡ã€‚
    """
    if os.path.isfile(csv_path):
        df_raw = pd.read_csv(csv_path, dtype=str, index_col=0).reset_index().rename(columns={"index": "race_id"})
    else:
        return pd.DataFrame()

    df = df_raw.copy()
    df["ç€é †"] = pd.to_numeric(df["ç€é †"], errors="coerce")
    df["äººæ°—"] = pd.to_numeric(df["äººæ°—"], errors="coerce")
    df["course_len"] = pd.to_numeric(df["course_len"], errors="coerce")

    # å‡ºèµ°é ­æ•°ã‚’ç®—å‡ºï¼ˆrace_idå˜ä½ï¼‰
    df["é ­æ•°"] = df.groupby("race_id")["é¦¬ç•ª"].transform("count")

    all_results = []
    courses = name_header.COURSE_LISTS[place_id - 1]

    for race_type, course_len in courses:
        base_data = df[
            (df["race_type"] == race_type) &
            (df["course_len"] == float(course_len))
        ]

        for cls in CLASSES:
            for grd in GROUNDS:
                tmp = base_data.copy()
                if cls != "all":
                    tmp = tmp[tmp["class"] == cls]
                if grd != "å…¨":
                    tmp = tmp[tmp["ground_state"] == grd]

                if top3:
                    tmp = tmp[tmp["ç€é †"].isin([1, 2, 3])]
                else:
                    tmp = tmp[tmp["ç€é †"] == 1]

                if tmp.empty:
                    # ãƒ‡ãƒ¼ã‚¿ãªã—ã§ã‚‚å…¨äººæ°—åˆ—ã‚’åŸ‹ã‚ã‚‹
                    result = {
                        "race_type": race_type,
                        "course_len": int(course_len),
                        "ground_state": grd,
                        "class": cls,
                        "avg_pop": None,
                    }
                    for i in range(1, 19):
                        result[f"pop_{i}_count"] = 0
                    all_results.append(result)
                    continue

                # å¹³å‡äººæ°—ï¼ˆ18é ­ç«‹ã¦æ›ç®—ï¼‰
                tmp["norm_pop"] = tmp["äººæ°—"] * (18 / tmp["é ­æ•°"])
                avg_pop = tmp["norm_pop"].mean()

                # äººæ°—åˆ¥å‹åˆ©æ•°ã‚«ã‚¦ãƒ³ãƒˆ
                pop_counts = tmp["äººæ°—"].value_counts().to_dict()

                result = {
                    "race_type": race_type,
                    "course_len": int(course_len),
                    "ground_state": grd,
                    "class": cls,
                    "avg_pop": round(avg_pop, 2) if avg_pop else None,
                }

                for i in range(1, 19):
                    result[f"pop_{i}_count"] = int(pop_counts.get(i, 0))

                all_results.append(result)

    df_result = pd.DataFrame(all_results)
    df_result["race_type"] = pd.Categorical(df_result["race_type"], categories=["èŠ", "ãƒ€ãƒ¼ãƒˆ"], ordered=True)
    df_result["class"] = pd.Categorical(df_result["class"], categories=CLASSES, ordered=True)
    df_result["ground_state"] = pd.Categorical(df_result["ground_state"], categories=GROUNDS, ordered=True)

    df_result = df_result.sort_values(["race_type", "course_len", "class", "ground_state"]).reset_index(drop=True)

    cols = ["race_type", "course_len", "ground_state", "class", "avg_pop"] + [f"pop_{i}_count" for i in range(1, 19)]
    df_result = df_result.reindex(columns=cols)
    return df_result

def analyze_frame_and_horse_multi_years(base_dir, place_id, start_year):
    """
    å„å¹´åº¦ï¼ˆstart_yearã€œä»Šå¹´ï¼‰ã«ã¤ã„ã¦ã€æ ãƒ»é¦¬ç•ªã®å¹³å‡ã¨å‹ã¡æ•°ã‚’ç®—å‡ºã€‚
    å…¨å¹´åº¦ã‚’çµåˆã—ã€å…¨æœŸé–“ã®å¹³å‡ï¼ˆå¹³å‡å€¤ï¼‹åˆè¨ˆå‹åˆ©æ•°ï¼‰ã‚’ç”Ÿæˆã€‚
    """
    current_year = int(date.today().year)
    results_by_year = {}

    for year in range(start_year, current_year + 1):
        csv_path = os.path.join(base_dir, f"{year}_race_results.csv")
        if not os.path.exists(csv_path):
            print(f"âš ï¸ {csv_path} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
            continue

        print(f"ğŸ“˜ {year}å¹´ã®æ ãƒ»é¦¬ç•ªãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ä¸­ ...")
        df_year = analyze_average_frame_and_horse(csv_path, place_id)
        if not df_year.empty:
            df_year["year"] = year
            results_by_year[year] = df_year

    if not results_by_year:
        print("âŒ æœ‰åŠ¹ãªæ ãƒ»é¦¬ç•ªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return pd.DataFrame()

    combined_df = pd.concat(results_by_year.values(), ignore_index=True)

    # å¹³å‡å€¤ã‚«ãƒ©ãƒ ã¨åˆè¨ˆã‚«ãƒ©ãƒ ã‚’åˆ¤åˆ¥
    group_cols = ["race_type", "course_len", "ground_state", "class"]
    mean_cols = ["avg_frame", "avg_horse"]
    sum_cols = [c for c in combined_df.columns if c.startswith("frame_") or c.startswith("horse_") or c == "total_winners"]

    agg_dict = {c: "mean" for c in mean_cols}
    agg_dict.update({c: "sum" for c in sum_cols})

    total_df = (
        combined_df.groupby(group_cols, dropna=False)
        .agg(agg_dict)
        .round(2)
        .reset_index()
    )

    total_df["race_type"] = pd.Categorical(total_df["race_type"], categories=["èŠ", "ãƒ€ãƒ¼ãƒˆ"], ordered=True)
    total_df["class"] = pd.Categorical(total_df["class"], categories=CLASSES, ordered=True)
    total_df["ground_state"] = pd.Categorical(total_df["ground_state"], categories=GROUNDS, ordered=True)

    total_df = total_df.sort_values(["race_type", "course_len", "class", "ground_state"]).reset_index(drop=True)

    print(f"âœ… å…¨æœŸé–“å¹³å‡ï¼ˆ{start_year}ã€œ{current_year}ï¼‰ã®æ ãƒ»é¦¬ç•ªãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã—ã¾ã—ãŸã€‚")
    return total_df

def analyze_average_frame_and_horse(csv_path, place_id):
    """
    å‹ã¡é¦¬ã®ã€Œå¹³å‡æ ç•ªã€ã€Œå¹³å‡é¦¬ç•ªã€ã€Œå‹åˆ©æ•°ã€ãŠã‚ˆã³
    å„æ ãƒ»é¦¬ç•ªã®å‹ã¡æ•°ã‚’ race_type, course_len, ground_state, class ã”ã¨ã«ç®—å‡ºã€‚
    ï¼ˆäººæ°—åˆ†æã¨åŒã˜æ§‹é€ ãƒ»ä¸¦ã³é †ã§å…¨æ¡ä»¶ç”Ÿæˆï¼‰
    """
    if not os.path.isfile(csv_path):
        return pd.DataFrame()

    df_raw = pd.read_csv(csv_path, dtype=str, index_col=0).reset_index().rename(columns={"index": "race_id"})
    df = df_raw.copy()

    df["ç€é †"] = pd.to_numeric(df["ç€é †"], errors="coerce")
    df["æ ç•ª"] = pd.to_numeric(df["æ ç•ª"], errors="coerce")
    df["é¦¬ç•ª"] = pd.to_numeric(df["é¦¬ç•ª"], errors="coerce")
    df["course_len"] = pd.to_numeric(df["course_len"], errors="coerce")

    all_results = []
    courses = name_header.COURSE_LISTS[place_id - 1]

    for race_type, course_len in courses:
        for cls in CLASSES:
            for grd in GROUNDS:
                tmp = df[
                    (df["race_type"] == race_type) &
                    (df["course_len"] == float(course_len))
                ]

                if cls != "all":
                    tmp = tmp[tmp["class"] == cls]
                if grd != "å…¨":
                    tmp = tmp[tmp["ground_state"] == grd]

                if tmp.empty:
                    # ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã‚‚ç©ºè¡Œã‚’åŸ‹ã‚ã¦ãŠãï¼ˆäººæ°—ç‰ˆã¨åŒã˜ï¼‰
                    result = {
                        "race_type": race_type,
                        "course_len": int(course_len),
                        "ground_state": grd,
                        "class": cls,
                        "avg_frame": None,
                        "avg_horse": None,
                        "total_winners": 0
                    }
                    for i in range(1, 9):
                        result[f"frame_{i}_wins"] = 0
                    for j in range(1, 19):
                        result[f"horse_{j}_wins"] = 0
                    all_results.append(result)
                    continue

                winners = tmp[tmp["ç€é †"] == 1].copy()
                if winners.empty:
                    result = {
                        "race_type": race_type,
                        "course_len": int(course_len),
                        "ground_state": grd,
                        "class": cls,
                        "avg_frame": None,
                        "avg_horse": None,
                        "total_winners": 0
                    }
                    for i in range(1, 9):
                        result[f"frame_{i}_wins"] = 0
                    for j in range(1, 19):
                        result[f"horse_{j}_wins"] = 0
                    all_results.append(result)
                    continue

                avg_frame = winners["æ ç•ª"].mean()
                avg_horse = winners["é¦¬ç•ª"].mean()
                frame_counts = winners["æ ç•ª"].value_counts().reindex(range(1, 9), fill_value=0)
                horse_counts = winners["é¦¬ç•ª"].value_counts().reindex(range(1, 19), fill_value=0)

                result = {
                    "race_type": race_type,
                    "course_len": int(course_len),
                    "ground_state": grd,
                    "class": cls,
                    "avg_frame": round(avg_frame, 2) if not pd.isna(avg_frame) else None,
                    "avg_horse": round(avg_horse, 2) if not pd.isna(avg_horse) else None,
                    "total_winners": len(winners)
                }

                for i in range(1, 9):
                    result[f"frame_{i}_wins"] = frame_counts[i]
                for j in range(1, 19):
                    result[f"horse_{j}_wins"] = horse_counts[j]

                all_results.append(result)

    df_result = pd.DataFrame(all_results)

    # --- ã‚«ãƒ†ã‚´ãƒªé †ã‚’æŒ‡å®šï¼ˆäººæ°—é›†è¨ˆã¨åŒã˜ä¸¦ã³ï¼‰---
    df_result["race_type"] = pd.Categorical(df_result["race_type"], categories=["èŠ", "ãƒ€ãƒ¼ãƒˆ"], ordered=True)
    df_result["class"] = pd.Categorical(df_result["class"], categories=CLASSES, ordered=True)
    df_result["ground_state"] = pd.Categorical(df_result["ground_state"], categories=GROUNDS, ordered=True)

    df_result = df_result.sort_values(["race_type", "course_len", "class", "ground_state"]).reset_index(drop=True)

    base_cols = ["race_type", "course_len", "ground_state", "class", "avg_frame", "avg_horse", "total_winners"]
    frame_cols = [f"frame_{i}_wins" for i in range(1, 9)]
    horse_cols = [f"horse_{j}_wins" for j in range(1, 19)]

    df_result = df_result.reindex(columns=base_cols + frame_cols + horse_cols)

    return df_result

def analyze_average_frame_and_horse_top3(csv_path, place_id):
    """
    3ç€ä»¥å†…é¦¬ã®ã€Œå¹³å‡æ ç•ªã€ã€Œå¹³å‡é¦¬ç•ªã€ã€Œ3ç€å†…é¦¬æ•°ã€ãŠã‚ˆã³
    å„æ ãƒ»é¦¬ç•ªã”ã¨ã®3ç€å†…å›æ•°ã‚’ race_type, course_len, ground_state, class ã”ã¨ã«ç®—å‡ºã€‚
    """
    if not os.path.isfile(csv_path):
        return pd.DataFrame()

    df_raw = pd.read_csv(csv_path, dtype=str, index_col=0).reset_index().rename(columns={"index": "race_id"})
    df = df_raw.copy()

    # æ•°å€¤å¤‰æ›
    df["ç€é †"] = pd.to_numeric(df["ç€é †"], errors="coerce")
    df["æ ç•ª"] = pd.to_numeric(df["æ ç•ª"], errors="coerce")
    df["é¦¬ç•ª"] = pd.to_numeric(df["é¦¬ç•ª"], errors="coerce")
    df["course_len"] = pd.to_numeric(df["course_len"], errors="coerce")

    all_results = []
    courses = name_header.COURSE_LISTS[place_id - 1]

    for race_type, course_len in courses:
        for cls in CLASSES:
            for grd in GROUNDS:
                tmp = df[
                    (df["race_type"] == race_type) &
                    (df["course_len"] == float(course_len))
                ]

                if cls != "all":
                    tmp = tmp[tmp["class"] == cls]
                if grd != "å…¨":
                    tmp = tmp[tmp["ground_state"] == grd]

                if tmp.empty:
                    result = make_empty_record(race_type, course_len, grd, cls)
                    all_results.append(result)
                    continue

                top3 = tmp[tmp["ç€é †"] <= 3].copy()
                if top3.empty:
                    result = make_empty_record(race_type, course_len, grd, cls)
                    all_results.append(result)
                    continue

                avg_frame = top3["æ ç•ª"].mean()
                avg_horse = top3["é¦¬ç•ª"].mean()
                frame_counts = top3["æ ç•ª"].value_counts().reindex(range(1, 9), fill_value=0)
                horse_counts = top3["é¦¬ç•ª"].value_counts().reindex(range(1, 19), fill_value=0)

                result = {
                    "race_type": race_type,
                    "course_len": int(course_len),
                    "ground_state": grd,
                    "class": cls,
                    "avg_frame": round(avg_frame, 2) if not pd.isna(avg_frame) else None,
                    "avg_horse": round(avg_horse, 2) if not pd.isna(avg_horse) else None,
                    "total_top3": len(top3)
                }

                for i in range(1, 9):
                    result[f"frame_{i}_top3"] = frame_counts[i]
                for j in range(1, 19):
                    result[f"horse_{j}_top3"] = horse_counts[j]

                all_results.append(result)

    df_result = pd.DataFrame(all_results)

    # --- ä¸¦ã³é †ã‚’çµ±ä¸€ ---
    df_result["race_type"] = pd.Categorical(df_result["race_type"], categories=["èŠ", "ãƒ€ãƒ¼ãƒˆ"], ordered=True)
    df_result["class"] = pd.Categorical(df_result["class"], categories=CLASSES, ordered=True)
    df_result["ground_state"] = pd.Categorical(df_result["ground_state"], categories=GROUNDS, ordered=True)

    df_result = df_result.sort_values(["race_type", "course_len", "class", "ground_state"]).reset_index(drop=True)

    base_cols = ["race_type", "course_len", "ground_state", "class", "avg_frame", "avg_horse", "total_top3"]
    frame_cols = [f"frame_{i}_top3" for i in range(1, 9)]
    horse_cols = [f"horse_{j}_top3" for j in range(1, 19)]

    df_result = df_result.reindex(columns=base_cols + frame_cols + horse_cols)

    return df_result

def analyze_frame_and_horse_top3_multi_years(base_dir, place_id, start_year):
    """
    å„å¹´åº¦ï¼ˆstart_yearã€œä»Šå¹´ï¼‰ã«ã¤ã„ã¦ã€3ç€ä»¥å†…é¦¬ã®æ ãƒ»é¦¬ç•ªåˆ†æã‚’ç®—å‡ºã€‚
    å…¨å¹´åº¦ã‚’çµåˆã—ã¦å¹³å‡åŒ–ã—ã€å…¨æœŸé–“ã®å¹³å‡ã¨åˆè¨ˆã‚’ç”Ÿæˆã€‚
    """
    current_year = int(date.today().year)
    results_by_year = {}

    for year in range(start_year, current_year + 1):
        csv_path = os.path.join(base_dir, f"{year}_race_results.csv")
        if not os.path.exists(csv_path):
            print(f"âš ï¸ {csv_path} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
            continue

        print(f"ğŸ“˜ {year}å¹´ã®3ç€å†…ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ä¸­ ...")
        df_year = analyze_average_frame_and_horse_top3(csv_path, place_id)
        if not df_year.empty:
            df_year["year"] = year
            results_by_year[year] = df_year

    if not results_by_year:
        print("âŒ æœ‰åŠ¹ãª3ç€å†…ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return pd.DataFrame()

    combined_df = pd.concat(results_by_year.values(), ignore_index=True)

    group_cols = ["race_type", "course_len", "ground_state", "class"]
    mean_cols = ["avg_frame", "avg_horse"]
    sum_cols = [c for c in combined_df.columns if c.startswith("frame_") or c.startswith("horse_") or c == "total_top3"]

    agg_dict = {c: "mean" for c in mean_cols}
    agg_dict.update({c: "sum" for c in sum_cols})

    total_df = (
        combined_df.groupby(group_cols, dropna=False)
        .agg(agg_dict)
        .round(2)
        .reset_index()
    )

    total_df["race_type"] = pd.Categorical(total_df["race_type"], categories=["èŠ", "ãƒ€ãƒ¼ãƒˆ"], ordered=True)
    total_df["class"] = pd.Categorical(total_df["class"], categories=CLASSES, ordered=True)
    total_df["ground_state"] = pd.Categorical(total_df["ground_state"], categories=GROUNDS, ordered=True)

    total_df = total_df.sort_values(["race_type", "course_len", "class", "ground_state"]).reset_index(drop=True)

    print(f"âœ… å…¨æœŸé–“å¹³å‡ï¼ˆ{start_year}ã€œ{current_year}ï¼‰ã®3ç€å†…æ ãƒ»é¦¬ç•ªãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã—ã¾ã—ãŸã€‚")
    return total_df

def make_empty_record(race_type, course_len, grd, cls):
    """ç©ºãƒ‡ãƒ¼ã‚¿è¡Œã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ"""
    record = {
        "race_type": race_type,
        "course_len": int(course_len),
        "ground_state": grd,
        "class": cls,
        "avg_frame": None,
        "avg_horse": None,
        "total_top3": 0
    }
    for i in range(1, 9):
        record[f"frame_{i}_top3"] = 0
    for j in range(1, 19):
        record[f"horse_{j}_top3"] = 0
    return record



def update_horse_name_id_map(place_id, year):
    """
    æŒ‡å®šãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®ãƒ¬ãƒ¼ã‚¹çµæœCSVã‚’ã™ã¹ã¦èª­ã¿è¾¼ã¿ã€
    æ—¢å­˜ã® horse_name_id_map.csv ã«ãƒãƒ¼ã‚¸ã—ã¦æ›´æ–°ã™ã‚‹ã€‚

    Parameters
    ----------
    input_dir : str
        ãƒ¬ãƒ¼ã‚¹çµæœCSVã®æ ¼ç´ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆä¾‹: './RaceResults/'ï¼‰
    output_path : str
        å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆä¾‹: './horse_name_id_map.csv'ï¼‰
    """
    csv_file_path = os.path.join(name_header.DATA_PATH, "horse_id_map.csv")
    # --- æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ ---
    if os.path.exists(csv_file_path):
        existing_df = pd.read_csv(csv_file_path, dtype=str)
        print(f"ğŸ“˜ æ—¢å­˜ã®å¯¾å¿œè¡¨ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ ({len(existing_df)}ä»¶)")
    else:
        existing_df = pd.DataFrame(columns=["é¦¬å", "horse_id"])
        print("âš ï¸ æ—¢å­˜ã®å¯¾å¿œè¡¨ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚æ–°è¦ä½œæˆã—ã¾ã™ã€‚")

    # --- æ–°è¦ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ ---
    input_files = os.path.join(name_header.DATA_PATH, "RaceResults", name_header.PLACE_LIST[place_id - 1], f"{year}_race_results.csv")

    # --- å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ ---
    print()
    all_data = []
    if not os.path.exists(input_files):
        print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {input_files}")
    else:
        try:
            df = pd.read_csv(input_files, dtype=str)
            if "é¦¬å" in df.columns and "horse_id" in df.columns:
                all_data.append(df[["é¦¬å", "horse_id"]].dropna())
                print(f"ğŸ“— èª­ã¿è¾¼ã¿æˆåŠŸ: {input_files} ({len(df)}ä»¶)")
            else:
                print(f"âš ï¸ ã‚«ãƒ©ãƒ ä¸è¶³ã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—: {input_files}")
        except Exception as e:
            print(f"[WARN] {input_files} èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")

    if not all_data:
        print("âŒ æœ‰åŠ¹ãªCSVãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

     # --- çµåˆ ---
    new_df = pd.concat(all_data, ignore_index=True)
    merged_df = pd.concat([existing_df, new_df], ignore_index=True)

    # --- é‡è¤‡å‰Šé™¤ ---
    merged_df = merged_df.drop_duplicates(subset=["horse_id"], keep="first")
    merged_df = merged_df.drop_duplicates(subset=["é¦¬å"], keep="first")

    # --- horse_idé †ã«ã‚½ãƒ¼ãƒˆ ---
    merged_df = merged_df.sort_values(by="horse_id").reset_index(drop=True)

    # --- ä¿å­˜ ---
    merged_df.to_csv(csv_file_path, index=False, encoding="utf-8-sig")

    print(f"âœ… é¦¬åãƒ»horse_idå¯¾å¿œè¡¨ã‚’æ›´æ–°ã—ã¾ã—ãŸ ({len(merged_df)}ä»¶): {csv_file_path}")

if __name__ == '__main__':
    # for place_id in range(1, len(name_header.PLACE_LIST) + 1):
    #     for year in range(2019, 2026):
    #         update_horse_name_id_map(place_id,year)

    for place_id in range(1, len(name_header.PLACE_LIST) + 1):
        # å„å¹´ã®è¨˜éŒ²ã‚’è¨ˆç®—
        for year in range(2019,date.today().year + 1):
            csv_path = name_header.DATA_PATH + "//RaceResults//" + name_header.PLACE_LIST[place_id -1] + "//" + f"{year}_race_results.csv"
            result = analyze_average_pops(csv_path, place_id, False)
            if not result.empty:
                output_path = name_header.DATA_PATH + "//AveragePops//" + name_header.PLACE_LIST[place_id -1] + "//" + f"{year}_average_pops.csv"
                result.to_csv(output_path)
        # totalã®è¨˜éŒ²ã‚’è¨ˆç®—
        base_dir = name_header.DATA_PATH + "//RaceResults//" + name_header.PLACE_LIST[place_id -1] + "//"
        total_df = analyze_average_pop_multi_years(base_dir, place_id, 2019, False)
        total_ouutput_path = name_header.DATA_PATH + "//AveragePops//" + name_header.PLACE_LIST[place_id -1] + "//" + "total_average_pops.csv"
        total_df.to_csv(total_ouutput_path)