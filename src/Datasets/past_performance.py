import os
import re
import sys

from datetime import date, timedelta
import pandas as pd
import numpy as np
from tqdm import tqdm

# pycache ã‚’ç”Ÿæˆã—ãªã„
sys.dont_write_bytecode = True
sys.path.append(r"C:\keiba_ai\keiba_ai_ver2.0\libs")
import get_race_id
import name_header
import scraping
import analysis_race_info
import race_results

def past_performance_error(e):
    """ ã‚¨ãƒ©ãƒ¼æ™‚å‹•ä½œã‚’è¨˜è¼‰ã™ã‚‹ 
        Args:
            e (Exception) : ã‚¨ãƒ©ãƒ¼å†…å®¹ 
    """
    print(__name__ + ":" + __file__)
    print(f"{e.__class__.__name__}: {e}")

def make_past_performance_dataset(horse_id):
    """ hotse_idã‹ã‚‰ã€éå»æˆç¸¾ã®DataFrameã‚’ä½œæˆ 
        Args:
            horse_id (str) : horse_id
        Returns:
            DataFrame: horse_idã®éå»æˆç¸¾ã‚’DataFrameå‹ã§è¿”ã™    
    """
    url = 'https://db.netkeiba.com/horse/' + horse_id
    # ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°
    horse_results_df = scraping.scrape_df(url)
    # print(horse_results_df)
    try:
        # æ–°é¦¬æˆ¦ã®å ´åˆã‚’é™¤å¤–
        if len(horse_results_df) < 4:
            return pd.DataFrame()
        
        # éå»ã®ãƒ¬ãƒ¼ã‚¹çµæœãƒ†ãƒ¼ãƒ–ãƒ«ã‚’å–å¾—
        df = horse_results_df[3]
        
        #å—è³æ­´ãŒã‚ã‚‹é¦¬ã®å ´åˆã€3ç•ªç›®ã«å—è³æ­´ãƒ†ãƒ¼ãƒ–ãƒ«ãŒæ¥ã‚‹ãŸã‚ã€4ç•ªç›®ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã™ã‚‹
        if df.columns[0]=='å—è³æ­´':
            df = horse_results_df[4]

        # ä¸è¦ãªè¦ç´ ã‚’æ¶ˆå»ã™ã‚‹
        df = df.drop(columns = df.columns[5])
        df = df.drop(columns = df.columns[16 - 1])
        df = df.drop(columns = df.columns[19 - 2])
        df = df.drop(columns = df.columns[24 - 3])
        df = df.drop(columns = df.columns[25 - 4])
        df = df.drop(columns = df.columns[27 - 5])
        df = df.reset_index(drop = True)

        return df
    except Exception as e:
        print("error id:", horse_id)
        past_performance_error(e)
        return pd.DataFrame

def save_past_performance_dataset(horse_id, past_performance_df):
    """ past_performanceã®DataFrameã‚’ä¿å­˜ 
        Args:
            horse_id (int) :horse_id
            past_performance_df(pd.DataFrameï¼‰ : past_performanceã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
    """
    try:
        if any(past_performance_df):
            # csv/pickleã«ä¿å­˜
            past_performance_df.to_csv(name_header.DATA_PATH + "PastPerformance\\" + str(horse_id) + '.csv')
            past_performance_df.to_pickle(name_header.DATA_PATH + "PastPerformance\\" + str(horse_id) + '.pickle')
    except Exception as e:
            past_performance_error(e)

def get_past_performance_dataset(horse_id):
    """ past_performanceã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å–å¾— 
        Args:
            horse_id (int) :horse_id
    """

    # csvã‚’èª­ã¿è¾¼ã‚€ 
    path = name_header.DATA_PATH + "PastPerformance\\" + str(horse_id) + '.csv'
    if os.path.isfile(path):
        df = pd.read_csv(path, index_col = 0, dtype = str)
    else :
        df = pd.DataFrame()

    return df

def get_horse_id_from_peds_dataset(place_id, year):
    """  éå»ã®çµæœã‹ã‚‰horse_idã‚’æŠ½å‡º
    Args:
        place_id (int) : é–‹å‚¬ã‚³ãƒ¼ã‚¹id
        year(int) : é–‹å‚¬å¹´
    Returns:
        list(str): horse_idã®ãƒªã‚¹ãƒˆ    
    """
    # éå»ã®è¡€çµ±ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã™ã‚‹
    path = name_header.DATA_PATH + name_header.PLACE_LIST[place_id - 1] + "/" + str(year) + "_peds.csv"
    if os.path.isfile(path):
        df = pd.read_csv(path, index_col = 0)
    else :
        print("not_is_file:" + path)
        return []

    # horse_idã®ã¿ã‚’æŠ½å‡ºã—è¿”ã™
    return df.index

def get_horse_id_list_from_race_id_list(race_id_list):
    """ race_id_listã‹ã‚‰å‡ºèµ°é¦¬ã®horse_idã‚’å–å¾—
        Args:
            race_id(int) : race_id  
        Returns:
            horse_id_list : horse_idã®ãƒªã‚¹ãƒˆ
    """ 
    try:
        horse_id_list = []
        for race_id in race_id_list:
            horse_id_list.append(get_horse_id_from_race_id(race_id))
        horse_id_list = sum(horse_id_list, [])
        return horse_id_list
    except Exception as e:
            past_performance_error(e)
            return horse_id_list

def get_horse_id_from_race_id(race_id):
    """ race_idtã‹ã‚‰å‡ºèµ°é¦¬ã®horse_idã‚’å–å¾—
        Args:
            race_id(int) : race_id  
        Returns:
            horse_id_list : horse_idã®ãƒªã‚¹ãƒˆ
    """ 
    horse_id_list = []
    # race_idã‹ã‚‰å¹´,place_idã‚’æŠ½å‡º
    year = str(race_id)[0] + str(race_id)[1] + str(race_id)[2] + str(race_id)[3] 
    place_id = int(str(race_id)[4] + str(race_id)[5])

    # ãƒ¬ãƒ¼ã‚¹çµæœã‚’å–å¾—
    df = race_results.get_race_results_csv(place_id, year)
    if df.empty:
        return horse_id_list

    # race_idã®ãƒ¬ãƒ¼ã‚¹ã®ã¿ã‚’æŠ½å‡º
    df.index = df.index.astype(str)
    df = df[race_id:race_id]
    # horse_idã®ã¿ã‚’æŠ½å‡º
    horse_id_list = df.loc[:,"horse_id"].to_list()

    return horse_id_list

def get_past_race_id(horse_result):
    """ éå»ã®æˆç¸¾ã‚’race_id_listã«å¤‰æ›
        Args:
            horse_result(pd.DataFrame) : éå»æˆç¸¾ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ  
        Returns:
            race_id_list : race_idã®ãƒªã‚¹ãƒˆ
    """
    # print(len(horse_result))
    race_id_list = []
    for i in range(len(horse_result)):
        # å¹´ã®å–å¾—
        date = horse_result.at[i,"æ—¥ä»˜"]
        # print(date)
        year = re.findall(r"\d+", date)[0]
        # print(year)

        # é–‹å‚¬æƒ…å ±ã®å–å¾—
        kaisai = horse_result.at[i,"é–‹å‚¬"]
        # print(kaisai)
        course = re.sub(r"[0-9]+", "", kaisai)
        course_id = -1
        for id in range(len(name_header.NAME_LIST)):
            if course == name_header.NAME_LIST[id]:
                course_id = id + 1
                break

        if course_id > 0:
            times = re.findall(r"\d+", kaisai)[0]
            day = re.findall(r"\d+", kaisai)[1]
            race = horse_result.at[i,"R"]
            race_id = str(year) + str(course_id).zfill(2) + str(times).zfill(2) + str(day).zfill(2) + str(race).zfill(2)
            
        else : 
            race_id = str("nan")    
        race_id_list.append(race_id)
    
    return race_id_list

def get_past_race_info(horse_id, race_id, race_num):
    """å½“è©²ãƒ¬ãƒ¼ã‚¹ã‚ˆã‚Šéå»ã®æŒ‡å®šãƒ¬ãƒ¼ã‚¹æ•°å–å¾—
        Args:
            horse_id(int) : horse_id
            race_id(int) : race_id
            race_num(int) : æŠ½å‡ºã™ã‚‹ãƒ¬ãƒ¼ã‚¹æ•°
        Returns:
            horse_result : æŒ‡å®šãƒ¬ãƒ¼ã‚¹æ•°ã®éå»ãƒ¬ãƒ¼ã‚¹çµæœ
    """
    try: 
        # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®å–å¾—
        horse_result = get_past_performance_dataset(horse_id)
        # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒãªã„å ´åˆã¯æ–°è¦ä½œæˆ
        if horse_result.empty:
            horse_results_df = make_past_performance_dataset_from_race_results(str(horse_id))
            save_past_performance_dataset(str(horse_id), horse_results_df)
            horse_result = get_past_performance_dataset(horse_id)

        # å½“è©²ãƒ¬ãƒ¼ã‚¹ã‚ˆã‚Šéå»ã®ãƒ¬ãƒ¼ã‚¹ã‚’å–å¾—
        horse_result = reset_horse_result(horse_result, race_id)
        
        # æŒ‡å®šãƒ¬ãƒ¼ã‚¹æ•°å–å¾—
        if len(horse_result.index) > race_num:
            horse_result = horse_result[0:race_num]

        return horse_result
    except Exception as e:
        past_performance_error(e)
        return pd.DataFrame()

def reset_horse_result(horse_result, race_id):
    """éå»ã®æˆç¸¾ã®ã†ã¡race_idä»¥é™ã®ãƒ¬ãƒ¼ã‚¹ã‚’æ¶ˆå»
        Args:
            horse_result(pd.DataFrame) : éå»ã®ãƒ¬ãƒ¼ã‚¹çµæœ
            race_id(int) : race_id
        Returns:
            horse_result : race_idä»¥é™ã®éå»ãƒ¬ãƒ¼ã‚¹çµæœ
    """
    race_id_list = get_past_race_id(horse_result.reset_index())
    
    # race_idã€€ã¨ä¸€è‡´ã™ã‚‹å ´æ‰€ã‚’å–å¾—
    idx = -1
    for i in range(len(race_id_list)):
        if str(race_id) == race_id_list[i]:
            idx = i
            break
    
    # race_idã€€ä»¥é™ã‚’æ¶ˆå»
    new_horse_results = horse_result
    if idx > 0:
        if idx == len(race_id_list):
            new_horse_results = pd.DataFrame()
        else:
            new_horse_results = horse_result[idx + 1:len(race_id_list)]
    
    return new_horse_results.reset_index(drop = True)

def make_past_performanece_datasets(horse_id_list):
    """ horse_id_listã‹ã‚‰éå»æˆç¸¾ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆ  
        Args:
            horse_id_list : horse_idã®ãƒªã‚¹ãƒˆ
    """ 
    for horse_id in tqdm(horse_id_list):
        # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®å–å¾—
        horse_results_df = make_past_performance_dataset_from_race_results(str(horse_id))
        # print(horse_results_df)
        save_past_performance_dataset(str(horse_id), horse_results_df)

def make_past_performance_dataset_from_race_results(horse_id):
    """å…¨race_resultsã‹ã‚‰ horse_id ã®éå»æˆç¸¾ã‚’ past_performance å½¢å¼ã§ä½œæˆ"""
    all_race_df = []
    base_dir = name_header.DATA_PATH + "RaceResults"

    # --- RaceResultså…¨ä½“ã‚’èµ°æŸ»ã—ã¦å…¨ãƒ¬ãƒ¼ã‚¹æƒ…å ±ã‚’åé›† ---
    for place in sorted(os.listdir(base_dir)):
        place_path = os.path.join(base_dir, place)
        if not os.path.isdir(place_path):
            continue

        for file in sorted(os.listdir(place_path)):
            if not file.endswith("_race_results.csv"):
                continue
            csv_path = os.path.join(place_path, file)
            try:
                df = pd.read_csv(csv_path, dtype=str)
                if "horse_id" not in df.columns:
                    continue
                if "Unnamed: 0" in df.columns:
                    df = df.rename(columns={"Unnamed: 0": "race_id"})
                df["place_id"] = place  # é–‹å‚¬å ´
                all_race_df.append(df)
            except Exception as e:
                print(f"âš ï¸ {csv_path} èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

    if not all_race_df:
        print(f"âŒ RaceResultsãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return pd.DataFrame()

    full_df = pd.concat(all_race_df, ignore_index=True)
    full_df = full_df.fillna("")

    # å¯¾è±¡é¦¬ã®ã¿æŠ½å‡º
    df = full_df[full_df["horse_id"] == str(horse_id)].copy()
    if df.empty:
        print(f"âŒ horse_id={horse_id} ã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return pd.DataFrame()

    # --- race_idã”ã¨ã«ä»–é¦¬ãƒ‡ãƒ¼ã‚¿ã‚’å‚ç…§ã—ã¦æ´¾ç”Ÿæƒ…å ±ã‚’ç”Ÿæˆ ---
    records = []
    for _, row in df.iterrows():
        race_id = row["race_id"]
        same_race = full_df[full_df["race_id"] == race_id].copy()

        # é™¤å¤–ãƒ»å–æ¶ˆã¯é ­æ•°ã‹ã‚‰é™¤å¤–ï¼ˆä¸­æ­¢ã¯æ®‹ã™ï¼‰
        def valid_starter(r):
            txt = str(r["ç€é †"])
            if any(w in txt for w in ["é™¤", "å–", "å–æ¶ˆ"]):
                return False
            return True

        valid_starters = same_race[same_race.apply(valid_starter, axis=1)]
        headcount = len(valid_starters)

        # å‹ã¡é¦¬ãƒ»2ç€é¦¬
        first = valid_starters[valid_starters["ç€é †"] == "1"]
        second = valid_starters[valid_starters["ç€é †"] == "2"]
        first_name = first.iloc[0]["é¦¬å"] if not first.empty else ""
        second_name = second.iloc[0]["é¦¬å"] if not second.empty else ""

        # ã‚¿ã‚¤ãƒ å·®è¨ˆç®—
        def to_seconds(t):
            if not t or t in ["nan", "NaN", ""]:
                return np.nan
            t = t.replace("0:", "") if t.startswith("0:") else t
            parts = t.split(":")
            if len(parts) == 2:
                return float(parts[0]) * 60 + float(parts[1])
            return float(parts[-1])

        # --- ã‚¿ã‚¤ãƒ å·®è¨ˆç®—å‡¦ç† ---
        if any(x in str(row.get("ç€é †", "")) for x in ["é™¤", "å–", "ä¸­", "å¤±"]) or  not row.get("ã‚¿ã‚¤ãƒ "):
            # ä¸­æ­¢ãƒ¬ãƒ¼ã‚¹ã€ã¾ãŸã¯ã‚¿ã‚¤ãƒ æœªè¨˜éŒ² â†’ ç€å·®ã¯ NaN
            margin = np.nan
        else:
            this_time = to_seconds(row.get("ã‚¿ã‚¤ãƒ ", ""))
            first_time = to_seconds(first.iloc[0]["ã‚¿ã‚¤ãƒ "]) if not first.empty else np.nan
            second_time = to_seconds(second.iloc[0]["ã‚¿ã‚¤ãƒ "]) if not second.empty else np.nan

            margin = ""
            if not np.isnan(this_time) and not np.isnan(first_time):
                diff = round(this_time - first_time, 1)
                if str(row["ç€é †"]) == "1":
                    # 1ç€ã®å ´åˆï¼š2ç€ã¨ã®å·®ã‚’ãƒã‚¤ãƒŠã‚¹å€¤ã§è¡¨ç¤º
                    if not np.isnan(second_time):
                        diff_to_second = round(second_time - this_time, 1)
                        margin = f"-{diff_to_second:.1f}" if diff_to_second > 0 else "-0.0"
                    else:
                        margin = "-0.0"
                else:
                    margin = f"{diff:.1f}" if diff > 0 else ""

        # å‹ã¡é¦¬æ¬„
        if str(row["ç€é †"]) == "1":
            winner_text = f"({second_name})" if second_name else ""
        else:
            winner_text = first_name

        # --- çµ±ä¸€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆåŒ– ---
        record = {
            "race_id": race_id,
            "æ—¥ä»˜": row["date"].replace("å¹´", "/").replace("æœˆ", "/").replace("æ—¥", ""),
            "é–‹å‚¬": name_header.NAME_LIST[int(row["place_id"][:2]) - 1] if str(row["place_id"][:2]).isdigit() else "",
            "å¤©æ°—": row.get("weather", ""),
            "R": str(race_id)[-2:],
            "ãƒ¬ãƒ¼ã‚¹å": "",  # å¾Œã§race_name_mapã§è£œå®Œ
            "class": row.get("class", ""),
            "é ­æ•°": headcount,
            "æ ç•ª": row.get("æ ç•ª", ""),
            "é¦¬ç•ª": row.get("é¦¬ç•ª", ""),
            "ã‚ªãƒƒã‚º": row.get("å˜å‹", ""),
            "äººæ°—": row.get("äººæ°—", ""),
            "ç€é †": row.get("ç€é †", ""),
            "é¨æ‰‹": row.get("é¨æ‰‹", ""),
            "æ–¤é‡": row.get("æ–¤é‡", ""),
            "race_type": row.get("race_type", ""),
            "course_len": row.get("course_len", ""),
            "ground_state": row.get("ground_state", ""),
            "ã‚¿ã‚¤ãƒ ": row.get("ã‚¿ã‚¤ãƒ ", ""),
            "ç€å·®": margin,
            "é€šé": row.get("é€šé", ""),
            "ä¸Šã‚Š": row.get("ä¸Šã‚Š", ""),
            "é¦¬ä½“é‡": row.get("é¦¬ä½“é‡", ""),
            "å‹ã¡é¦¬ (2ç€é¦¬)": winner_text,
        }
        records.append(record)

    result_df = pd.DataFrame(records)

    # --- ãƒ¬ãƒ¼ã‚¹åè£œå®Œ ---
    race_name_map = {}
    race_time_dir = os.path.join(name_header.TEXT_PATH, "race_calendar/race_time_id_list")
    for file in os.listdir(race_time_dir):
        if not file.endswith(".csv"):
            continue
        try:
            df_info = pd.read_csv(os.path.join(race_time_dir, file), dtype=str)
            for _, r in df_info.iterrows():
                race_name_map[str(r["race_id"])] = str(r.get("race_name", ""))
        except Exception:
            continue
    result_df["ãƒ¬ãƒ¼ã‚¹å"] = result_df["race_id"].map(race_name_map).fillna("")

    # --- ä¸¦ã³é †çµ±ä¸€ ---
    out_cols = [
        "race_id", "æ—¥ä»˜", "é–‹å‚¬", "å¤©æ°—", "R", "ãƒ¬ãƒ¼ã‚¹å", "class", "é ­æ•°",
        "æ ç•ª", "é¦¬ç•ª", "ã‚ªãƒƒã‚º", "äººæ°—", "ç€é †", "é¨æ‰‹", "æ–¤é‡",
        "race_type", "course_len", "ground_state", "ã‚¿ã‚¤ãƒ ", "ç€å·®",
        "é€šé", "ä¸Šã‚Š", "é¦¬ä½“é‡", "å‹ã¡é¦¬ (2ç€é¦¬)"
    ]
    for c in out_cols:
        if c not in result_df.columns:
            result_df[c] = ""

    result_df = result_df[out_cols]

    # --- ã‚½ãƒ¼ãƒˆï¼ˆæ—¥ä»˜æ–°â†’å¤ï¼‰ ---
    try:
        result_df["æ—¥ä»˜_dt"] = pd.to_datetime(result_df["æ—¥ä»˜"], errors="coerce")
        result_df = result_df.sort_values("æ—¥ä»˜_dt", ascending=False).drop(columns=["æ—¥ä»˜_dt"])
    except Exception:
        pass

    # print(f"âœ… horse_id={horse_id} ã®éå»æˆç¸¾ {len(result_df)}ä»¶ã‚’æ•´å½¢ã—ã¾ã—ãŸã€‚")
    return result_df.reset_index(drop=True)

def normalize_past_performance_format(df_old: pd.DataFrame) -> pd.DataFrame:
    """
    æ—§ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®past_performanceã‚’æ–°ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«å¤‰æ›ã™ã‚‹
    """
    
    if df_old.empty:
        return pd.DataFrame()
    df = df_old.copy()

    # âœ… æ–°ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆåˆ¤å®š
    new_columns = {
        "race_id", "æ—¥ä»˜", "é–‹å‚¬", "å¤©æ°—", "R", "ãƒ¬ãƒ¼ã‚¹å", "class", "é ­æ•°",
        "æ ç•ª", "é¦¬ç•ª", "ã‚ªãƒƒã‚º", "äººæ°—", "ç€é †", "é¨æ‰‹", "æ–¤é‡",
        "race_type", "course_len", "ground_state", "ã‚¿ã‚¤ãƒ ", "ç€å·®",
        "é€šé", "ä¸Šã‚Š", "é¦¬ä½“é‡", "å‹ã¡é¦¬ (2ç€é¦¬)"
    }
    if new_columns.issubset(set(df_old.columns)):
        # ã™ã§ã«æ–°å½¢å¼ â†’ è»½å¾®ãªæ•´å½¢ã®ã¿
        
        df["æ—¥ä»˜"] = pd.to_datetime(df["æ—¥ä»˜"], errors="coerce").dt.strftime("%Y/%m/%d")
        if "class" in df.columns:
            df["class"] = df["class"].apply(normalize_class_text)
        if "ãƒ¬ãƒ¼ã‚¹å" in df.columns:
            df["ãƒ¬ãƒ¼ã‚¹å"] = df["ãƒ¬ãƒ¼ã‚¹å"].apply(clean_race_name)
        return df

    # --- åˆ—åã‚’æ¨™æº–åŒ– ---
    rename_map = {
        "å¤© æ°—": "å¤©æ°—",
        "æ  ç•ª": "æ ç•ª",
        "é¦¬ ç•ª": "é¦¬ç•ª",
        "é ­ æ•°": "é ­æ•°",
        "ã‚ª ãƒƒ ã‚º": "ã‚ªãƒƒã‚º",
        "äºº æ°—": "äººæ°—",
        "ç€ é †": "ç€é †",
        "æ–¤ é‡": "æ–¤é‡",
        "é¦¬ å ´": "ground_state",
    }
    df = df.rename(columns=rename_map)

    # --- ä¸è¦ãªåˆ—å‰Šé™¤ ---
    drop_cols = ["ãƒšãƒ¼ã‚¹"]
    df = df.drop(columns=[c for c in drop_cols if c in df.columns], errors="ignore")

    # ãƒ¬ãƒ¼ã‚¹ã‚¯ãƒ©ã‚¹åˆ¤å®šé–¢æ•°
    def extract_class(race_name):
        if pd.isna(race_name):
            return ""
        name = str(race_name)

        # åŠè§’å…¨è§’ã‚’çµ±ä¸€ã—ã¦å¤§æ–‡å­—åŒ–
        name = name.upper().replace("ï¼§", "G")

        # ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒ—ï¼ˆé †åºãŒé‡è¦ï¼šä¸Šä½ã‚«ãƒ†ã‚´ãƒªã‚’å…ˆã«ï¼‰
        patterns = [
            (r"G[â… I1]", "ã‚ªãƒ¼ãƒ—ãƒ³"),
            (r"G[â…¡I2]", "ã‚ªãƒ¼ãƒ—ãƒ³"),
            (r"G[â…¢I3]", "ã‚ªãƒ¼ãƒ—ãƒ³"),
            (r"OP|OPEN|ã‚ªãƒ¼ãƒ—ãƒ³|ï½µï½°ï¾Œï¾Ÿï¾", "ã‚ªãƒ¼ãƒ—ãƒ³"),
            (r"3å‹ã‚¯ãƒ©ã‚¹|ï¼“å‹|ä¸‰å‹", "3å‹ã‚¯ãƒ©ã‚¹"),
            (r"2å‹ã‚¯ãƒ©ã‚¹|ï¼’å‹|äºŒå‹", "2å‹ã‚¯ãƒ©ã‚¹"),
            (r"1å‹ã‚¯ãƒ©ã‚¹|ï¼‘å‹|ä¸€å‹", "1å‹ã‚¯ãƒ©ã‚¹"),
            (r"æœªå‹åˆ©", "æœªå‹åˆ©"),
            (r"æ–°é¦¬", "æ–°é¦¬"),
        ]

        for pat, label in patterns:
            if re.search(pat, name):
                return label
        return ""  # ä¸æ˜ãªå ´åˆã¯ç©ºç™½
    
    # --- classåˆ—ã‚’è¿½åŠ  ---
    if "class" not in df.columns:
        df["class"] = df["ãƒ¬ãƒ¼ã‚¹å"].apply(extract_class)


    # --- è·é›¢åˆ—ã‚’åˆ†å‰²ï¼ˆèŠ2200 â†’ race_type="èŠ", course_len="2200"ï¼‰ ---
    df["race_type"] = df["è·é›¢"].astype(str).str.extract(r"([èŠãƒ€éšœ])")[0].fillna("")
    df["course_len"] = df["è·é›¢"].astype(str).str.extract(r"(\d+)")[0].fillna("")

    # --- é¦¬ä½“é‡æ•´å½¢ ---
    df["é¦¬ä½“é‡"] = df["é¦¬ä½“é‡"].astype(str).str.extract(r"(\d+)")[0].fillna("")

    # --- ã‚ªãƒƒã‚º, äººæ°—, æ ç•ª, é¦¬ç•ªãªã©ã®æ•´å½¢ ---
    for col in ["ã‚ªãƒƒã‚º", "äººæ°—", "æ ç•ª", "é¦¬ç•ª", "æ–¤é‡"]:
        df[col] = df[col].astype(str).str.replace(",", "").str.strip()
        df[col] = df[col].replace("", None)

    # --- ç€å·®ã‚’æ•°å€¤åŒ– ---
    def parse_margin(x):
        try:
            s = str(x).replace("âˆ’", "-").replace("+", "").strip()
            return float(s)
        except:
            return ""
    df["ç€å·®"] = df["ç€å·®"].apply(parse_margin)

    # --- æ—¥ä»˜æ•´å½¢ ---
    df["æ—¥ä»˜"] = (
        df["æ—¥ä»˜"].astype(str)
        .str.replace("å¹´", "/", regex=False)
        .str.replace("æœˆ", "/", regex=False)
        .str.replace("æ—¥", "", regex=False)
        .str.strip()
    )

    # --- race_idç”Ÿæˆ ---
    place_map = {
        "æœ­å¹Œ": "01", "å‡½é¤¨": "02", "ç¦å³¶": "03", "æ–°æ½Ÿ": "04", "æ±äº¬": "05", "ä¸­å±±": "06",
        "ä¸­äº¬": "07", "äº¬éƒ½": "08", "é˜ªç¥": "09", "å°å€‰": "10"
    }
    def make_race_id(row):
        # å¹´
        year = str(pd.to_datetime(row["æ—¥ä»˜"]).year)
        # é–‹å‚¬ã®å·¦æ•°å­—ï¼ˆä¾‹: 3ä¸­äº¬1 â†’ 3ï¼‰
        m = re.match(r"(\d+)([^\d]+)(\d+)", str(row["é–‹å‚¬"]))
        if not m:
            return None
        left_num, course_name, right_num = m.groups()
        # é–‹å‚¬åœ°ã‚³ãƒ¼ãƒ‰
        course_code = place_map.get(course_name, "00")
        # Rã‚’2æ¡ã«
        r_num = f"{int(float(row['R'])):02d}"
        # race_idçµ„ã¿ç«‹ã¦
        return f"{year}{course_code}{int(left_num):02d}{int(right_num):02d}{r_num}"
    
    df["race_id"] = df.apply(make_race_id, axis=1)

    # --- é–‹å‚¬åã‚’ç°¡ç•¥åŒ–ï¼ˆä¾‹: "3ä¸­äº¬1"â†’"ä¸­äº¬"ï¼‰ ---
    df["é–‹å‚¬"] = df["é–‹å‚¬"].astype(str).str.replace(r"^\d+", "", regex=True).str.replace(r"\d+$", "", regex=True).str.strip()

    # --- ã‚«ãƒ©ãƒ æ•´åˆ— ---
    expected_cols = [
        "race_id", "æ—¥ä»˜", "é–‹å‚¬", "å¤©æ°—", "R", "ãƒ¬ãƒ¼ã‚¹å", "class", "é ­æ•°", "æ ç•ª", "é¦¬ç•ª",
        "ã‚ªãƒƒã‚º", "äººæ°—", "ç€é †", "é¨æ‰‹", "æ–¤é‡", "race_type", "course_len",
        "ground_state", "ã‚¿ã‚¤ãƒ ", "ç€å·®", "é€šé", "ä¸Šã‚Š", "é¦¬ä½“é‡", "å‹ã¡é¦¬ (2ç€é¦¬)"
    ]
    df = df[[c for c in expected_cols if c in df.columns]]

    # --- ã‚½ãƒ¼ãƒˆï¼ˆæ—¥ä»˜é™é †ï¼‰ ---
    try:
        df["æ—¥ä»˜_dt"] = pd.to_datetime(df["æ—¥ä»˜"], errors="coerce")
        df = df.sort_values("æ—¥ä»˜_dt", ascending=False).drop(columns=["æ—¥ä»˜_dt"])
    except Exception:
        pass

    print(f"âœ… {len(df)}ä»¶ã®æ—§ãƒ‡ãƒ¼ã‚¿ã‚’æ–°ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«å¤‰æ›ã—ã¾ã—ãŸã€‚")
    return df

def normalize_class_text(text):
    """
    ã‚¯ãƒ©ã‚¹è¡¨è¨˜ã‚’æ­£è¦åŒ–ã™ã‚‹ã€‚
    ä¾‹: 'ï¼“å‹ã‚¯ãƒ©ã‚¹' â†’ '3å‹ã‚¯ãƒ©ã‚¹'
    """
    if pd.isna(text):
        return text
    # å…¨è§’â†’åŠè§’å¤‰æ›ï¼ˆæ•°å­—ãƒ»è‹±å­—ï¼‰
    text = text.translate(str.maketrans(
        "ï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™ï¼¡ï¼¢ï¼£ï¼¤ï¼¥ï¼¦ï¼§ï¼¨ï¼©ï¼ªï¼«ï¼¬ï¼­ï¼®ï¼¯ï¼°ï¼±ï¼²ï¼³ï¼´ï¼µï¼¶ï¼·ï¼¸ï¼¹ï¼ºï½ï½‚ï½ƒï½„ï½…ï½†ï½‡ï½ˆï½‰ï½Šï½‹ï½Œï½ï½ï½ï½ï½‘ï½’ï½“ï½”ï½•ï½–ï½—ï½˜ï½™ï½š",
        "0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz"
    ))
    # ã‚ˆãã‚ã‚‹ãƒ–ãƒ¬ã‚’ä¿®æ­£
    text = re.sub(r'\s+', '', text)  # ã‚¹ãƒšãƒ¼ã‚¹å‰Šé™¤
    text = re.sub(r'å‹ï½¸ï¾—ï½½', 'å‹ã‚¯ãƒ©ã‚¹', text)
    text = re.sub(r'æœªå‹åˆ©', 'æœªå‹åˆ©', text)
    text = re.sub(r'æ–°é¦¬', 'æ–°é¦¬', text)
    text = re.sub(r'ï½¸ï¾—ï½½', 'ã‚¯ãƒ©ã‚¹', text)
    text = re.sub(r'ï½µï½°ï¾Œï¾Ÿï¾', 'ã‚ªãƒ¼ãƒ—ãƒ³', text)
    return text

def clean_race_name(text):
    """
    ãƒ¬ãƒ¼ã‚¹åã«å«ã¾ã‚Œã‚‹ï¼ˆ3å‹ã‚¯ãƒ©ã‚¹ï¼‰ãªã©ã®è¡¨è¨˜ã‚’å‰Šé™¤ã™ã‚‹ã€‚
    ä¾‹: 'ãƒ ãƒ¼ãƒ³ãƒ©ã‚¤ãƒˆH(3å‹ã‚¯ãƒ©ã‚¹)' â†’ 'ãƒ ãƒ¼ãƒ³ãƒ©ã‚¤ãƒˆH'
    """
    if pd.isna(text):
        return text
    # ()å†…ã®ã‚¯ãƒ©ã‚¹ãƒ»ãƒ¬ãƒ™ãƒ«è¡¨è¨˜ã‚’å‰Šé™¤
    text = re.sub(r'ï¼ˆ.*?ã‚¯ãƒ©ã‚¹.*?ï¼‰', '', text)  # å…¨è§’æ‹¬å¼§å¯¾å¿œ
    text = re.sub(r'\(.*?ã‚¯ãƒ©ã‚¹.*?\)', '', text)  # åŠè§’æ‹¬å¼§å¯¾å¿œ
    text = re.sub(r'\s+$', '', text)  # æœ«å°¾ã®ç©ºç™½ã‚’å‰Šé™¤
    return text

def update_past_performance(horse_id):
    # --- æ—¢å­˜ã® past_performance èª­ã¿è¾¼ã¿ ---
    past_performance_root = name_header.DATA_PATH + "PastPerformance"
    past_path = os.path.join(past_performance_root, f"{horse_id}.csv")
    if os.path.exists(past_path):
        past_df = pd.read_csv(past_path, dtype=str)
    else:
        past_df = pd.DataFrame()
        print("âš ï¸ éå»ãƒ‡ãƒ¼ã‚¿ãªã—ï¼ˆæ–°è¦ä½œæˆï¼‰")

    print("processing:", horse_id)
    # --- ğŸ§© ä¸¡æ–¹ã‚’å…±é€šãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«æƒãˆã‚‹ ---
    existing_df_norm = normalize_past_performance_format(past_df)
    # print(existing_df_norm)
   

    # --- è¿½åŠ ãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒ¼ã‚¸ ---
    add_df = make_past_performance_dataset_from_race_results(horse_id)
    # print(add_df)
    if not add_df.empty:
        updated_df = pd.concat([existing_df_norm, add_df], ignore_index=True)
        updated_df = updated_df.drop_duplicates(subset=["race_id"], keep="first")
    else:
        updated_df = existing_df_norm
        print("âœ… æ–°ã—ã„ãƒ¬ãƒ¼ã‚¹ã¯ã‚ã‚Šã¾ã›ã‚“")

    # --- æ—¥ä»˜é †ã«ä¸¦ã¹æ›¿ãˆ ---
    if "æ—¥ä»˜" in updated_df.columns:
        updated_df["æ—¥ä»˜"] = pd.to_datetime(updated_df["æ—¥ä»˜"], errors="coerce")
        updated_df = updated_df.sort_values("æ—¥ä»˜", ascending=False).reset_index(drop=True)
    
    # æ—¥ä»˜ã‚’æ­£è¦åŒ–ï¼ˆä¾‹ï¼š2025-09-07 â†’ 2025/09/07ï¼‰
    updated_df["æ—¥ä»˜"] = pd.to_datetime(updated_df["æ—¥ä»˜"], errors="coerce").dt.strftime("%Y/%m/%d")

    # ã‚¯ãƒ©ã‚¹è¡¨è¨˜ã‚’æ­£è¦åŒ–
    updated_df["class"] = updated_df["class"].apply(normalize_class_text)

    # ãƒ¬ãƒ¼ã‚¹åã®ã‚¯ãƒ©ã‚¹è¡¨è¨˜ã‚’å‰Šé™¤
    if "ãƒ¬ãƒ¼ã‚¹å" in updated_df.columns:
        updated_df["ãƒ¬ãƒ¼ã‚¹å"] = updated_df["ãƒ¬ãƒ¼ã‚¹å"].apply(clean_race_name)

    # ===== åˆ—ã®ä¸¦ã³çµ±ä¸€ =====
    expected_cols = [
        "race_id", "æ—¥ä»˜", "é–‹å‚¬", "å¤©æ°—", "R", "ãƒ¬ãƒ¼ã‚¹å", "class", "é ­æ•°",
        "æ ç•ª", "é¦¬ç•ª", "ã‚ªãƒƒã‚º", "äººæ°—", "ç€é †", "é¨æ‰‹", "æ–¤é‡",
        "race_type", "course_len", "ground_state", "ã‚¿ã‚¤ãƒ ", "ç€å·®",
        "é€šé", "ä¸Šã‚Š", "é¦¬ä½“é‡", "å‹ã¡é¦¬ (2ç€é¦¬)"
    ]
    # å­˜åœ¨ã—ãªã„åˆ—ã‚’è£œå®Œï¼ˆNaNã§ï¼‰
    for col in expected_cols:
        if col not in updated_df.columns:
            updated_df[col] = pd.NA
    updated_df = updated_df[expected_cols]

    # --- ä¿å­˜ ---
    os.makedirs(past_performance_root, exist_ok=True)
    updated_df.to_csv(past_path, index=False, encoding="utf-8-sig")
    print(f"ğŸ’¾ ä¿å­˜å®Œäº†: {past_path} ï¼ˆ{len(updated_df)} ä»¶ï¼‰")

    return updated_df

def make_past_performance_dataset_from_race_id_list(race_id_list):
    """ race_id_listã‹ã‚‰éå»æˆç¸¾ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆ  
        Args:
            race_id_list : race_idã®ãƒªã‚¹ãƒˆ
    """ 
    horse_id_list = get_horse_id_list_from_race_id_list(race_id_list)
    if any(horse_id_list):
        make_past_performanece_datasets(horse_id_list)

def weekly_update_past_performance(day = date.today()):
    """ æŒ‡å®šã—ãŸæ—¥ã«ã¡ã‹ã‚‰ã€ï¼‘é€±é–“åˆ†ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ›´æ–°  
        Args:
            day(Date) : æ—¥ï¼ˆåˆæœŸå€¤ï¼šä»Šæ—¥ï¼‰
    """ 
    for place_id in tqdm(range(1, len(name_header.PLACE_LIST) + 1)):
        print("[WeeklyUpdate]", name_header.PLACE_LIST[place_id -1] , "PastPerformance")
        race_id_list = get_race_id.get_past_weekly_id(place_id, day)
        make_past_performance_dataset_from_race_id_list(race_id_list)
        
def monthly_update_past_performance(day = date.today()):
    """ æŒ‡å®šã—ãŸæ—¥ã«ã¡ã¾ã§ã®ãã®å¹´ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ›´æ–°  
        Args:
            day(Date) : æ—¥ï¼ˆåˆæœŸå€¤ï¼šä»Šæ—¥ï¼‰
    """ 
    for place_id in tqdm(range(1, len(name_header.PLACE_LIST) + 1)):
        print("[MonthlyUpdate]", name_header.PLACE_LIST[place_id -1],  "PastPerformance")
        race_id_list = get_race_id.get_past_year_id(place_id, day)
        make_past_performance_dataset_from_race_id_list(race_id_list)

def make_all_past_performance(year = date.today().year):
    """ æŒ‡å®šã—ãŸå¹´ã¾ã§ã®ã€ã™ã¹ã¦ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆ 
        Args:
            day(Date) : æ—¥ï¼ˆåˆæœŸå€¤ï¼šä»Šæ—¥ï¼‰
    """ 
    for y in range(2019, year + 1):
        for place_id in range(1, len(name_header.PLACE_LIST) + 1):
            print("[NewMake]" + str(y) + ":" + name_header.PLACE_LIST[place_id -1] + " PastPerformance")
            race_id_list = get_race_id.get_year_id_all(place_id,y)
            make_past_performance_dataset_from_race_id_list(race_id_list)

if __name__ == "__main__":
    monthly_update_past_performance()
